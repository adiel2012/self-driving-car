{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Week 7: Localization and Mapping\n\n## Module II: Perception & Localization\n\n### Topics Covered\n\n- Global Navigation Satellite Systems (GNSS/GPS)\n- Inertial Measurement Units (IMU) and Dead Reckoning\n- Particle Filters for Global Localization (Monte Carlo Localization)\n- Simultaneous Localization and Mapping (SLAM)\n- High-Definition (HD) Maps and Map Matching\n- Multi-Sensor Fusion for Robust Localization\n\n---\n\n## Learning Objectives\n\nBy the end of this notebook, you will be able to:\n\n1. Understand GPS/GNSS principles, error sources, and accuracy levels\n2. Implement IMU-based dead reckoning and understand drift accumulation\n3. Build a complete Particle Filter for global localization with resampling\n4. Implement EKF-SLAM to simultaneously build a map and localize\n5. Use HD maps for precise lane-level localization via map matching\n6. Design multi-sensor fusion architectures for robust localization\n7. Evaluate localization accuracy and understand failure modes\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle, Ellipse\nfrom matplotlib.animation import FuncAnimation\nfrom scipy.stats import multivariate_normal\nfrom collections import defaultdict\n\n# Set random seed for reproducibility\nnp.random.seed(42)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Global Navigation Satellite Systems (GNSS/GPS)\n\nGNSS provides global position estimates by triangulating signals from satellites. GPS is the most widely known GNSS operated by the United States.\n\n### How GPS Works\n\n**Trilateration Principle:**\n- Satellites continuously broadcast their position and time\n- GPS receiver measures time delay to calculate distance to each satellite\n- Need at least 4 satellites for 3D position (x, y, z) + clock bias\n\n**Position Calculation:**\n\nDistance to satellite $i$:\n$$\\rho_i = c \\cdot \\Delta t_i$$\n\nWhere:\n- $c$ = speed of light (≈ 3 × 10⁸ m/s)\n- $\\Delta t_i$ = time delay from satellite $i$\n\n**Trilateration Equations:**\n$$\\sqrt{(x - x_i)^2 + (y - y_i)^2 + (z - z_i)^2} = \\rho_i$$\n\nFor each satellite $i \\in \\{1, 2, 3, 4\\}$.\n\n### Error Sources\n\n1. **Atmospheric Delays**\n   - Ionospheric delay: ±5-10 meters\n   - Tropospheric delay: ±0.5-5 meters\n\n2. **Multipath Effects**\n   - Signal reflections from buildings/terrain\n   - Urban canyons: ±10-50 meters\n\n3. **Satellite Geometry (DOP - Dilution of Precision)**\n   - Poor geometry → large errors\n   - GDOP (Geometric DOP), HDOP (Horizontal), VDOP (Vertical)\n\n4. **Clock Errors**\n   - Satellite clock drift\n   - Receiver clock bias\n\n5. **Selective Availability** (historical, now disabled)\n\n### GPS Accuracy Levels\n\n| System | Accuracy | Notes |\n|--------|----------|-------|\n| Standard GPS | ±5-10m | Consumer devices |\n| DGPS (Differential) | ±1-3m | Ground-based corrections |\n| RTK GPS | ±2cm | Real-time kinematic, requires base station |\n| PPP (Precise Point) | ±10cm | Post-processing |\n\n### Limitations for Autonomous Vehicles\n\n- **Update Rate**: 1-10 Hz (too slow for high-speed control)\n- **Latency**: 100-200ms\n- **Availability**: Poor in tunnels, parking garages, urban canyons\n- **Accuracy**: Insufficient for lane-level localization (need ±10cm)\n\n**Solution**: Fuse GPS with other sensors (IMU, odometry, cameras, LIDAR) using Kalman Filters or Particle Filters."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Simple HD Map representation and localization simulation\n\nclass HDMap:\n    def __init__(self):\n        \"\"\"Simple HD Map with lane boundaries and landmarks\"\"\"\n        # Create a curved road - compute all points first\n        s_values = np.linspace(0, 50, 100)\n        \n        # Centerline (curved path)\n        x_values = s_values\n        y_values = 5 * np.sin(s_values / 10)\n        \n        # Compute heading from gradient\n        dx = np.gradient(x_values)\n        dy = np.gradient(y_values)\n        headings = np.arctan2(dy, dx)\n        \n        # Lane boundaries (offset from centerline)\n        lane_width = 3.5\n        \n        # Left boundary\n        x_left = x_values - lane_width/2 * np.sin(headings)\n        y_left = y_values + lane_width/2 * np.cos(headings)\n        \n        # Right boundary\n        x_right = x_values + lane_width/2 * np.sin(headings)\n        y_right = y_values - lane_width/2 * np.cos(headings)\n        \n        self.road_centerline = np.column_stack([x_values, y_values])\n        self.lane_left = np.column_stack([x_left, y_left])\n        self.lane_right = np.column_stack([x_right, y_right])\n        \n        # Add some landmark features (poles, signs)\n        self.landmarks = np.array([\n            [10, 8],\n            [20, 7],\n            [30, 8],\n            [40, 7]\n        ])\n    \n    def get_closest_point_on_centerline(self, position):\n        \"\"\"Find closest point on road centerline\"\"\"\n        distances = np.linalg.norm(self.road_centerline - position, axis=1)\n        idx = np.argmin(distances)\n        return self.road_centerline[idx], idx\n    \n    def visualize(self, ax):\n        \"\"\"Draw HD map on axis\"\"\"\n        ax.plot(self.road_centerline[:, 0], self.road_centerline[:, 1], \n               'k--', linewidth=1, label='Centerline')\n        ax.plot(self.lane_left[:, 0], self.lane_left[:, 1], \n               'y-', linewidth=2, label='Lane Boundaries')\n        ax.plot(self.lane_right[:, 0], self.lane_right[:, 1], 'y-', linewidth=2)\n        ax.scatter(self.landmarks[:, 0], self.landmarks[:, 1], \n                  c='red', s=100, marker='^', label='Landmarks', zorder=10)\n\n\ndef demonstrate_hd_map_localization():\n    \"\"\"Demonstrate localization using HD map matching\"\"\"\n    \n    # Create HD map\n    hd_map = HDMap()\n    \n    # Simulate vehicle trajectory (with GPS noise)\n    true_trajectory = []\n    noisy_gps_trajectory = []\n    \n    for i in range(0, 80, 2):\n        # True position (on centerline)\n        true_pos = hd_map.road_centerline[i]\n        true_trajectory.append(true_pos)\n        \n        # Noisy GPS\n        gps_pos = true_pos + np.random.randn(2) * 3  # ±3m GPS noise\n        noisy_gps_trajectory.append(gps_pos)\n    \n    true_trajectory = np.array(true_trajectory)\n    noisy_gps_trajectory = np.array(noisy_gps_trajectory)\n    \n    # Map-matched trajectory (project GPS onto road)\n    map_matched_trajectory = []\n    \n    for gps_pos in noisy_gps_trajectory:\n        closest_point, _ = hd_map.get_closest_point_on_centerline(gps_pos)\n        map_matched_trajectory.append(closest_point)\n    \n    map_matched_trajectory = np.array(map_matched_trajectory)\n    \n    # Visualization\n    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n    \n    # Left: Map with trajectories\n    ax = axes[0]\n    hd_map.visualize(ax)\n    \n    ax.plot(true_trajectory[:, 0], true_trajectory[:, 1], \n           'g-', linewidth=3, label='True Position', zorder=5)\n    ax.scatter(noisy_gps_trajectory[:, 0], noisy_gps_trajectory[:, 1], \n              c='red', s=30, alpha=0.5, label='Noisy GPS', zorder=3)\n    ax.plot(map_matched_trajectory[:, 0], map_matched_trajectory[:, 1], \n           'b-', linewidth=2, label='Map-Matched', zorder=4)\n    \n    ax.set_xlabel('X Position (m)')\n    ax.set_ylabel('Y Position (m)')\n    ax.set_title('HD Map Localization')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    ax.axis('equal')\n    \n    # Right: Error comparison\n    ax2 = axes[1]\n    \n    gps_error = np.linalg.norm(noisy_gps_trajectory - true_trajectory, axis=1)\n    map_matched_error = np.linalg.norm(map_matched_trajectory - true_trajectory, axis=1)\n    \n    steps = np.arange(len(gps_error))\n    ax2.plot(steps, gps_error, 'r-', linewidth=2, label='GPS Error', alpha=0.7)\n    ax2.plot(steps, map_matched_error, 'b-', linewidth=2, label='Map-Matched Error')\n    ax2.axhline(np.mean(gps_error), color='r', linestyle='--', alpha=0.5,\n               label=f'Mean GPS: {np.mean(gps_error):.2f}m')\n    ax2.axhline(np.mean(map_matched_error), color='b', linestyle='--', alpha=0.5,\n               label=f'Mean Matched: {np.mean(map_matched_error):.2f}m')\n    \n    ax2.set_xlabel('Time Step')\n    ax2.set_ylabel('Position Error (m)')\n    ax2.set_title('Localization Accuracy Comparison')\n    ax2.legend()\n    ax2.grid(True)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"GPS Mean Error: {np.mean(gps_error):.2f} m\")\n    print(f\"Map-Matched Mean Error: {np.mean(map_matched_error):.2f} m\")\n    print(f\"Improvement: {(1 - np.mean(map_matched_error)/np.mean(gps_error))*100:.1f}%\")\n\ndemonstrate_hd_map_localization()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Complete Particle Filter Implementation\n\nclass ParticleFilter:\n    \"\"\"Monte Carlo Localization with landmark-based sensing.\"\"\"\n    \n    def __init__(self, n_particles, map_limits, landmarks):\n        \"\"\"\n        Args:\n            n_particles: Number of particles\n            map_limits: [x_min, x_max, y_min, y_max]\n            landmarks: Nx2 array of landmark positions\n        \"\"\"\n        self.n_particles = n_particles\n        self.map_limits = map_limits\n        self.landmarks = landmarks\n        \n        # Initialize particles uniformly over map (global localization)\n        self.particles = self._initialize_particles()\n        self.weights = np.ones(n_particles) / n_particles\n        \n        # Motion model noise\n        self.motion_noise_std = np.array([0.1, 0.1, 0.05])  # [x, y, theta]\n        \n        # Sensor model noise\n        self.sensor_noise_std = np.array([0.5, 0.1])  # [range, bearing]\n        \n    def _initialize_particles(self):\n        \"\"\"Initialize particles uniformly over the map.\"\"\"\n        x_min, x_max, y_min, y_max = self.map_limits\n        \n        particles = np.zeros((self.n_particles, 3))  # [x, y, theta]\n        particles[:, 0] = np.random.uniform(x_min, x_max, self.n_particles)\n        particles[:, 1] = np.random.uniform(y_min, y_max, self.n_particles)\n        particles[:, 2] = np.random.uniform(-np.pi, np.pi, self.n_particles)\n        \n        return particles\n    \n    def predict(self, control):\n        \"\"\"\n        Motion update: apply control with noise to each particle.\n        \n        Args:\n            control: [dx, dy, dtheta] - motion command\n        \"\"\"\n        # Add noise to control\n        noise = np.random.randn(self.n_particles, 3) * self.motion_noise_std\n        \n        # Update particles\n        self.particles[:, 0] += control[0] + noise[:, 0]\n        self.particles[:, 1] += control[1] + noise[:, 1]\n        self.particles[:, 2] += control[2] + noise[:, 2]\n        \n        # Normalize angles\n        self.particles[:, 2] = np.arctan2(np.sin(self.particles[:, 2]), \n                                           np.cos(self.particles[:, 2]))\n    \n    def update(self, measurement):\n        \"\"\"\n        Measurement update: compute weights based on sensor likelihood.\n        \n        Args:\n            measurement: [range, bearing] to a landmark\n        \"\"\"\n        # For each particle, compute expected measurement to closest landmark\n        for i in range(self.n_particles):\n            x, y, theta = self.particles[i]\n            \n            # Find closest landmark\n            distances = np.linalg.norm(self.landmarks - np.array([x, y]), axis=1)\n            closest_idx = np.argmin(distances)\n            lx, ly = self.landmarks[closest_idx]\n            \n            # Expected measurement\n            expected_range = np.sqrt((lx - x)**2 + (ly - y)**2)\n            expected_bearing = np.arctan2(ly - y, lx - x) - theta\n            expected_bearing = np.arctan2(np.sin(expected_bearing), \n                                           np.cos(expected_bearing))\n            \n            # Measurement likelihood (Gaussian)\n            range_error = measurement[0] - expected_range\n            bearing_error = measurement[1] - expected_bearing\n            bearing_error = np.arctan2(np.sin(bearing_error), \n                                        np.cos(bearing_error))\n            \n            # Compute weight (likelihood)\n            weight = np.exp(-0.5 * (\n                (range_error / self.sensor_noise_std[0])**2 +\n                (bearing_error / self.sensor_noise_std[1])**2\n            ))\n            \n            self.weights[i] = weight\n        \n        # Normalize weights\n        self.weights += 1e-300  # Avoid divide by zero\n        self.weights /= np.sum(self.weights)\n    \n    def resample(self):\n        \"\"\"Low-variance resampling.\"\"\"\n        N = self.n_particles\n        new_particles = []\n        \n        # Cumulative sum\n        c = np.cumsum(self.weights)\n        \n        # Start at random position\n        u = np.random.uniform(0, 1/N)\n        \n        i = 0\n        for j in range(N):\n            # Evenly spaced samples\n            threshold = u + j / N\n            \n            # Find particle\n            while threshold > c[i]:\n                i += 1\n            \n            new_particles.append(self.particles[i].copy())\n        \n        self.particles = np.array(new_particles)\n        self.weights = np.ones(N) / N\n    \n    def effective_sample_size(self):\n        \"\"\"Compute effective sample size.\"\"\"\n        return 1.0 / np.sum(self.weights ** 2)\n    \n    def estimate(self):\n        \"\"\"Return weighted mean of particles.\"\"\"\n        mean_x = np.sum(self.weights * self.particles[:, 0])\n        mean_y = np.sum(self.weights * self.particles[:, 1])\n        \n        # Circular mean for angle\n        sin_sum = np.sum(self.weights * np.sin(self.particles[:, 2]))\n        cos_sum = np.sum(self.weights * np.cos(self.particles[:, 2]))\n        mean_theta = np.arctan2(sin_sum, cos_sum)\n        \n        return np.array([mean_x, mean_y, mean_theta])\n\n\n# Simulation: Robot moving in environment with landmarks\n\nnp.random.seed(42)\n\n# Environment setup\nmap_limits = [0, 50, 0, 50]\nlandmarks = np.array([\n    [10, 10],\n    [40, 10],\n    [10, 40],\n    [40, 40],\n    [25, 25]\n])\n\n# True robot trajectory (circular path)\nn_steps = 50\ntrue_trajectory = []\nestimated_trajectory = []\n\n# Initial true position\ntrue_pos = np.array([25.0, 15.0, 0.0])\n\n# Create particle filter\npf = ParticleFilter(n_particles=300, map_limits=map_limits, landmarks=landmarks)\n\n# Simulate\nfor step in range(n_steps):\n    # True motion (circular path)\n    velocity = 1.0\n    angular_vel = 0.15\n    dt = 0.5\n    \n    control = np.array([\n        velocity * np.cos(true_pos[2]) * dt,\n        velocity * np.sin(true_pos[2]) * dt,\n        angular_vel * dt\n    ])\n    \n    # Update true position\n    true_pos += control\n    true_pos[2] = np.arctan2(np.sin(true_pos[2]), np.cos(true_pos[2]))\n    true_trajectory.append(true_pos.copy())\n    \n    # Particle filter prediction\n    pf.predict(control)\n    \n    # Generate measurement (to closest landmark from true position)\n    distances = np.linalg.norm(landmarks - true_pos[:2], axis=1)\n    closest_idx = np.argmin(distances)\n    lx, ly = landmarks[closest_idx]\n    \n    true_range = np.sqrt((lx - true_pos[0])**2 + (ly - true_pos[1])**2)\n    true_bearing = np.arctan2(ly - true_pos[1], lx - true_pos[0]) - true_pos[2]\n    true_bearing = np.arctan2(np.sin(true_bearing), np.cos(true_bearing))\n    \n    # Add measurement noise\n    measurement = np.array([\n        true_range + np.random.randn() * 0.5,\n        true_bearing + np.random.randn() * 0.1\n    ])\n    \n    # Particle filter update\n    pf.update(measurement)\n    \n    # Resample if needed\n    if pf.effective_sample_size() < pf.n_particles / 2:\n        pf.resample()\n    \n    # Get estimate\n    estimate = pf.estimate()\n    estimated_trajectory.append(estimate.copy())\n\ntrue_trajectory = np.array(true_trajectory)\nestimated_trajectory = np.array(estimated_trajectory)\n\n# Visualization\nfig = plt.figure(figsize=(18, 6))\n\n# Plot 1: Full trajectory with particles (final step)\nax1 = fig.add_subplot(1, 3, 1)\n\n# Draw landmarks\nax1.scatter(landmarks[:, 0], landmarks[:, 1], c='red', s=200, marker='^', \n            edgecolors='black', linewidths=2, label='Landmarks', zorder=10)\n\n# Draw particles (final step)\nax1.scatter(pf.particles[:, 0], pf.particles[:, 1], c='blue', s=10, alpha=0.3, \n            label=f'Particles (N={pf.n_particles})')\n\n# Draw trajectories\nax1.plot(true_trajectory[:, 0], true_trajectory[:, 1], 'g-', \n         linewidth=3, label='True Trajectory', zorder=5)\nax1.plot(estimated_trajectory[:, 0], estimated_trajectory[:, 1], 'r--', \n         linewidth=2, label='PF Estimate', zorder=4)\n\n# Mark start and end\nax1.scatter([true_trajectory[0, 0]], [true_trajectory[0, 1]], \n            c='green', s=300, marker='o', edgecolors='black', linewidths=2, \n            label='Start', zorder=11)\nax1.scatter([true_trajectory[-1, 0]], [true_trajectory[-1, 1]], \n            c='orange', s=300, marker='s', edgecolors='black', linewidths=2, \n            label='End', zorder=11)\n\nax1.set_xlabel('X (m)', fontsize=12)\nax1.set_ylabel('Y (m)', fontsize=12)\nax1.set_title('Particle Filter Localization', fontsize=14, fontweight='bold')\nax1.legend(fontsize=10)\nax1.grid(True, alpha=0.3)\nax1.set_xlim(map_limits[:2])\nax1.set_ylim(map_limits[2:])\nax1.set_aspect('equal')\n\n# Plot 2: Error over time\nax2 = fig.add_subplot(1, 3, 2)\n\nerror = np.linalg.norm(estimated_trajectory[:, :2] - true_trajectory[:, :2], axis=1)\nsteps = np.arange(len(error))\n\nax2.plot(steps, error, 'b-', linewidth=2)\nax2.axhline(np.mean(error), color='r', linestyle='--', linewidth=2, \n            label=f'Mean: {np.mean(error):.2f}m')\nax2.fill_between(steps, 0, error, alpha=0.3)\n\nax2.set_xlabel('Time Step', fontsize=12)\nax2.set_ylabel('Position Error (m)', fontsize=12)\nax2.set_title('Localization Accuracy', fontsize=14, fontweight='bold')\nax2.legend(fontsize=11)\nax2.grid(True, alpha=0.3)\n\n# Plot 3: Particle convergence visualization (showing 5 snapshots)\nax3 = fig.add_subplot(1, 3, 3)\n\nsnapshot_steps = [0, 10, 20, 30, n_steps-1]\ncolors = plt.cm.viridis(np.linspace(0, 1, len(snapshot_steps)))\n\n# Draw landmarks\nax3.scatter(landmarks[:, 0], landmarks[:, 1], c='red', s=150, marker='^', \n            edgecolors='black', linewidths=1.5, zorder=10)\n\n# Draw true trajectory\nax3.plot(true_trajectory[:, 0], true_trajectory[:, 1], 'g-', \n         linewidth=2, alpha=0.5, label='True Path', zorder=5)\n\n# Particle spread at different times (we can't show historical particles, \n# so let's just show error bars)\nfor i, step_idx in enumerate(snapshot_steps):\n    if step_idx < len(estimated_trajectory):\n        ax3.scatter([estimated_trajectory[step_idx, 0]], \n                   [estimated_trajectory[step_idx, 1]], \n                   c=[colors[i]], s=100, marker='o', edgecolors='black',\n                   label=f'Step {step_idx}', zorder=6)\n\nax3.set_xlabel('X (m)', fontsize=12)\nax3.set_ylabel('Y (m)', fontsize=12)\nax3.set_title('Particle Filter Convergence', fontsize=14, fontweight='bold')\nax3.legend(fontsize=9, loc='upper right')\nax3.grid(True, alpha=0.3)\nax3.set_xlim(map_limits[:2])\nax3.set_ylim(map_limits[2:])\nax3.set_aspect('equal')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"=\" * 70)\nprint(\"PARTICLE FILTER LOCALIZATION RESULTS\")\nprint(\"=\" * 70)\nprint(f\"Number of particles: {pf.n_particles}\")\nprint(f\"Number of landmarks: {len(landmarks)}\")\nprint(f\"Number of time steps: {n_steps}\")\nprint(f\"\\nLocalization Error:\")\nprint(f\"  Mean error: {np.mean(error):.3f} m\")\nprint(f\"  Max error: {np.max(error):.3f} m\")\nprint(f\"  Min error: {np.min(error):.3f} m\")\nprint(f\"  Final error: {error[-1]:.3f} m\")\nprint(f\"\\nFinal Effective Sample Size: {pf.effective_sample_size():.1f}\")\nprint(f\"Resampling threshold: {pf.n_particles / 2:.1f}\")\nprint(\"=\" * 70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Particle Filter for Global Localization\n\n**Particle Filter** (Monte Carlo Localization) is a non-parametric Bayes filter that represents the belief as a set of weighted particles.\n\n### Why Particle Filters?\n\n**Advantages over Kalman Filters**:\n- ✅ Can represent **multi-modal** distributions (multiple hypotheses)\n- ✅ No Gaussian assumption (works with arbitrary sensor models)\n- ✅ Can handle **global localization** (unknown initial position)\n- ✅ Naturally handles **non-linear** motion and sensor models\n\n**Disadvantages**:\n- ❌ Computationally expensive (need 100s-1000s of particles)\n- ❌ Can suffer from **particle deprivation** (all particles have low weight)\n- ❌ Requires careful tuning of noise parameters\n\n---\n\n### Algorithm Overview\n\n**Representation**: Belief is a set of N particles:\n$$\\mathcal{X}_t = \\{x_t^{[1]}, x_t^{[2]}, ..., x_t^{[N]}\\}$$\n\nEach particle $x_t^{[i]}$ represents a hypothesis of the robot's pose: $[x, y, \\theta]$.\n\n**Algorithm** (4 steps):\n\n1. **Prediction** (Motion Update):\n   - For each particle, apply motion model with noise\n   - $x_t^{[i]} \\sim p(x_t | u_t, x_{t-1}^{[i]})$\n\n2. **Measurement Update** (Weight Update):\n   - Compute importance weight for each particle\n   - $w_t^{[i]} = p(z_t | x_t^{[i]})$\n   - Higher weight if sensor measurement matches particle's expected measurement\n\n3. **Normalization**:\n   - Normalize weights: $w_t^{[i]} = \\frac{w_t^{[i]}}{\\sum_j w_t^{[j]}}$\n\n4. **Resampling**:\n   - Draw N new particles from old particles with probability proportional to weight\n   - Prevents particle degeneracy\n\n---\n\n### Motion Model\n\n**Odometry-based** (most common for wheeled robots):\n\nGiven control $u_t = [\\Delta x, \\Delta y, \\Delta \\theta]$:\n\n$$x_t^{[i]} = x_{t-1}^{[i]} + \\Delta x + \\mathcal{N}(0, \\sigma_x^2)$$\n$$y_t^{[i]} = y_{t-1}^{[i]} + \\Delta y + \\mathcal{N}(0, \\sigma_y^2)$$\n$$\\theta_t^{[i]} = \\theta_{t-1}^{[i]} + \\Delta \\theta + \\mathcal{N}(0, \\sigma_\\theta^2)$$\n\nNoise $\\sigma$ captures uncertainty in motion.\n\n---\n\n### Sensor Model\n\n**Landmark-based** (common for localization):\n\nMeasure distance and bearing to known landmarks:\n$$z = [r, \\phi]$$\n\nWhere:\n- $r$ = distance to landmark\n- $\\phi$ = bearing (angle) to landmark\n\n**Expected measurement** for particle $x^{[i]} = [x, y, \\theta]$:\n\n$$\\hat{r} = \\sqrt{(x_L - x)^2 + (y_L - y)^2}$$\n$$\\hat{\\phi} = \\text{atan2}(y_L - y, x_L - x) - \\theta$$\n\n**Likelihood** (probability of measurement given particle):\n\n$$p(z | x^{[i]}) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(r - \\hat{r})^2}{2\\sigma_r^2} - \\frac{(\\phi - \\hat{\\phi})^2}{2\\sigma_\\phi^2}\\right)$$\n\n---\n\n### Resampling\n\n**Why**: After many iterations, few particles have significant weight → inefficient.\n\n**Effective Sample Size** (ESS):\n$$N_{eff} = \\frac{1}{\\sum_{i=1}^{N} (w^{[i]})^2}$$\n\n**Resample when**: $N_{eff} < N_{threshold}$ (e.g., N/2).\n\n**Methods**:\n\n1. **Multinomial Resampling** (simple):\n   - Draw N samples with replacement from $\\mathcal{X}_t$ with probability $w^{[i]}$\n\n2. **Systematic Resampling** (better):\n   - Deterministic, low variance\n   - Single random number, evenly spaced samples\n\n3. **Stratified Resampling**\n\n**Low Variance Resampling** (Systematic):\n```python\ndef low_variance_resample(particles, weights):\n    N = len(particles)\n    new_particles = []\n    \n    # Cumulative sum\n    c = np.cumsum(weights)\n    \n    # Start at random position\n    u = np.random.uniform(0, 1/N)\n    \n    i = 0\n    for j in range(N):\n        # Evenly spaced samples\n        threshold = u + j / N\n        \n        # Find particle\n        while threshold > c[i]:\n            i += 1\n        \n        new_particles.append(particles[i].copy())\n    \n    return new_particles\n```\n\n---\n\n### Kidnapped Robot Problem\n\n**Challenge**: Robot is \"kidnapped\" (teleported to unknown location).\n\n**Solution**: **Random particle injection**\n- Occasionally inject uniform random particles (5-10%)\n- Helps recover from catastrophic failures\n- Trade-off: Reduces tracking accuracy\n\n---\n\n### Convergence\n\n**Global Localization**: Start with uniform distribution over entire map.\n\n**Convergence criteria**:\n- Particles converge to a small region\n- Low variance in particle distribution\n- High maximum weight\n\n**Failure modes**:\n- **Particle deprivation**: All particles far from true pose\n- **Symmetry**: Multiple similar locations (e.g., identical hallways)\n\n---\n\n### Computational Complexity\n\n- **Prediction**: $O(N)$ - apply motion model to N particles\n- **Update**: $O(N \\cdot M)$ - N particles, M landmarks\n- **Resampling**: $O(N)$\n\n**Total**: $O(N \\cdot M)$ per time step.\n\n**Typical values**: N = 100-1000 particles, runs at 10-30 Hz on modern CPUs.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# IMU Dead Reckoning Simulation\n\nfrom dataclasses import dataclass\n\n@dataclass\nclass IMUReading:\n    \"\"\"IMU sensor reading.\"\"\"\n    acceleration: np.ndarray  # [ax, ay] in m/s²\n    angular_velocity: float   # omega in rad/s\n    timestamp: float\n\nclass IMUDeadReckoning:\n    \"\"\"Simple 2D IMU-based dead reckoning.\"\"\"\n    \n    def __init__(self, initial_pose, acc_noise_std=0.02, gyro_noise_std=0.01):\n        \"\"\"\n        Args:\n            initial_pose: [x, y, theta]\n            acc_noise_std: Accelerometer noise (m/s²)\n            gyro_noise_std: Gyroscope noise (rad/s)\n        \"\"\"\n        self.pose = np.array(initial_pose, dtype=float)  # [x, y, theta]\n        self.velocity = np.array([0.0, 0.0])  # [vx, vy]\n        \n        self.acc_noise_std = acc_noise_std\n        self.gyro_noise_std = gyro_noise_std\n        \n        # Sensor biases (constant drift)\n        self.acc_bias = np.array([0.005, 0.003])  # Small constant bias\n        self.gyro_bias = 0.002  # rad/s\n        \n    def update(self, imu_reading, dt):\n        \"\"\"\n        Update pose using IMU reading.\n        \n        Args:\n            imu_reading: IMUReading object\n            dt: Time step (seconds)\n        \"\"\"\n        # Add noise and bias to measurements\n        acc_measured = imu_reading.acceleration + self.acc_bias + \\\n                       np.random.randn(2) * self.acc_noise_std\n        gyro_measured = imu_reading.angular_velocity + self.gyro_bias + \\\n                        np.random.randn() * self.gyro_noise_std\n        \n        # Rotate acceleration to global frame\n        theta = self.pose[2]\n        R = np.array([[np.cos(theta), -np.sin(theta)],\n                      [np.sin(theta), np.cos(theta)]])\n        acc_global = R @ acc_measured\n        \n        # Update velocity\n        self.velocity += acc_global * dt\n        \n        # Update position\n        self.pose[0] += self.velocity[0] * dt + 0.5 * acc_global[0] * dt**2\n        self.pose[1] += self.velocity[1] * dt + 0.5 * acc_global[1] * dt**2\n        \n        # Update orientation\n        self.pose[2] += gyro_measured * dt\n        \n        # Normalize angle to [-pi, pi]\n        self.pose[2] = np.arctan2(np.sin(self.pose[2]), np.cos(self.pose[2]))\n        \n        return self.pose.copy()\n\n# Simulate vehicle motion with IMU\nnp.random.seed(42)\n\n# Ground truth trajectory: circular motion\ndt = 0.1  # 10 Hz update rate\nT = 20    # 20 seconds\nn_steps = int(T / dt)\n\n# True vehicle motion\ntrue_positions = []\nimu_positions = []\ngps_positions = []\n\n# Initial state\ntrue_pos = np.array([0.0, 0.0, 0.0])  # [x, y, theta]\ntrue_vel = 2.0  # m/s\nangular_vel = 0.3  # rad/s (turning)\n\n# Initialize IMU dead reckoning\nimu_dr = IMUDeadReckoning(initial_pose=true_pos.copy())\n\n# GPS parameters\ngps_update_rate = 1.0  # 1 Hz\ngps_noise_std = 2.0    # 2 meter standard deviation\n\nfor i in range(n_steps):\n    t = i * dt\n    \n    # True motion (circular path)\n    true_pos[2] += angular_vel * dt  # Update heading\n    true_pos[0] += true_vel * np.cos(true_pos[2]) * dt\n    true_pos[1] += true_vel * np.sin(true_pos[2]) * dt\n    true_positions.append(true_pos[:2].copy())\n    \n    # Generate IMU reading (true acceleration in body frame)\n    # Centripetal acceleration for circular motion\n    a_tangential = 0.0  # Constant speed\n    a_centripetal = true_vel * angular_vel  # v * omega\n    \n    # In body frame: forward = tangential, left = centripetal\n    acc_body = np.array([a_tangential, a_centripetal])\n    \n    imu_reading = IMUReading(\n        acceleration=acc_body,\n        angular_velocity=angular_vel,\n        timestamp=t\n    )\n    \n    # Update IMU dead reckoning\n    imu_pos = imu_dr.update(imu_reading, dt)\n    imu_positions.append(imu_pos[:2].copy())\n    \n    # GPS update (slower rate)\n    if i % int(gps_update_rate / dt) == 0:\n        gps_pos = true_pos[:2] + np.random.randn(2) * gps_noise_std\n        gps_positions.append(gps_pos)\n\ntrue_positions = np.array(true_positions)\nimu_positions = np.array(imu_positions)\ngps_positions = np.array(gps_positions)\n\n# Visualization\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Left: Trajectories\nax1 = axes[0]\nax1.plot(true_positions[:, 0], true_positions[:, 1], \n         'g-', linewidth=3, label='True Trajectory', zorder=5)\nax1.plot(imu_positions[:, 0], imu_positions[:, 1], \n         'r-', linewidth=2, alpha=0.7, label='IMU Dead Reckoning', zorder=4)\nax1.scatter(gps_positions[:, 0], gps_positions[:, 1], \n            c='blue', s=50, marker='x', label='GPS (1 Hz)', zorder=3)\n\nax1.set_xlabel('X Position (m)', fontsize=12)\nax1.set_ylabel('Y Position (m)', fontsize=12)\nax1.set_title('IMU Dead Reckoning vs GPS', fontsize=14, fontweight='bold')\nax1.legend(fontsize=11)\nax1.grid(True, alpha=0.3)\nax1.axis('equal')\n\n# Mark start and end\nax1.scatter([0], [0], c='green', s=200, marker='o', edgecolors='black', \n            linewidths=2, label='Start', zorder=10)\nax1.scatter([true_positions[-1, 0]], [true_positions[-1, 1]], \n            c='red', s=200, marker='s', edgecolors='black', \n            linewidths=2, label='End', zorder=10)\n\n# Right: Error over time\nax2 = axes[1]\n\nimu_error = np.linalg.norm(imu_positions - true_positions, axis=1)\ntime_steps = np.arange(len(imu_error)) * dt\n\nax2.plot(time_steps, imu_error, 'r-', linewidth=2, label='IMU Position Error')\nax2.set_xlabel('Time (s)', fontsize=12)\nax2.set_ylabel('Position Error (m)', fontsize=12)\nax2.set_title('IMU Drift Over Time', fontsize=14, fontweight='bold')\nax2.grid(True, alpha=0.3)\nax2.legend(fontsize=11)\n\n# Add drift rate annotation\nfinal_error = imu_error[-1]\ndrift_rate = final_error / T\nax2.text(0.5, 0.95, f'Final error: {final_error:.2f} m\\nDrift rate: {drift_rate:.3f} m/s',\n         transform=ax2.transAxes, fontsize=11, verticalalignment='top',\n         bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n\nplt.tight_layout()\nplt.show()\n\nprint(\"=\" * 70)\nprint(\"IMU DEAD RECKONING ANALYSIS\")\nprint(\"=\" * 70)\nprint(f\"Simulation time: {T} seconds\")\nprint(f\"IMU update rate: {1/dt:.0f} Hz\")\nprint(f\"GPS update rate: {gps_update_rate} Hz\")\nprint(f\"\\nIMU Sensor Parameters:\")\nprint(f\"  Accelerometer noise: {imu_dr.acc_noise_std:.3f} m/s²\")\nprint(f\"  Accelerometer bias: {imu_dr.acc_bias}\")\nprint(f\"  Gyroscope noise: {imu_dr.gyro_noise_std:.3f} rad/s\")\nprint(f\"  Gyroscope bias: {imu_dr.gyro_bias:.4f} rad/s\")\nprint(f\"\\nPosition Error:\")\nprint(f\"  Initial: {imu_error[0]:.2f} m\")\nprint(f\"  Final: {imu_error[-1]:.2f} m\")\nprint(f\"  Mean: {np.mean(imu_error):.2f} m\")\nprint(f\"  Drift rate: {drift_rate:.3f} m/s\")\nprint(f\"\\nConclusion: IMU alone drifts unboundedly. GPS fusion required!\")\nprint(\"=\" * 70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Inertial Measurement Units (IMU) and Dead Reckoning\n\nAn **IMU** measures acceleration and angular velocity using accelerometers and gyroscopes. Combined with GPS, IMUs provide high-frequency pose updates.\n\n### IMU Components\n\n**Accelerometer** (3-axis):\n- Measures specific force (acceleration - gravity)\n- Output: $\\mathbf{a} = [a_x, a_y, a_z]^T$ in m/s²\n- Noise: Bias drift, white noise\n\n**Gyroscope** (3-axis):\n- Measures angular velocity\n- Output: $\\boldsymbol{\\omega} = [\\omega_x, \\omega_y, \\omega_z]^T$ in rad/s\n- Noise: Bias drift (major issue for integration)\n\n**Magnetometer** (optional):\n- Measures magnetic field for heading\n- Subject to magnetic interference (motors, metal)\n\n---\n\n### Dead Reckoning with IMU\n\n**Integrate acceleration to get velocity, then position**:\n\n$$\\mathbf{v}_{t+1} = \\mathbf{v}_t + \\mathbf{a}_t \\cdot \\Delta t$$\n\n$$\\mathbf{p}_{t+1} = \\mathbf{p}_t + \\mathbf{v}_t \\cdot \\Delta t + \\frac{1}{2} \\mathbf{a}_t \\cdot \\Delta t^2$$\n\n**Integrate angular velocity to get orientation**:\n\n$$\\theta_{t+1} = \\theta_t + \\omega_t \\cdot \\Delta t$$\n\n---\n\n### Error Accumulation (Drift)\n\n**Problem**: Integration amplifies noise → unbounded error growth.\n\n**Acceleration noise** → Velocity error grows linearly → Position error grows quadratically.\n\n**Example**: \n- Accelerometer bias: 0.01 m/s²\n- After 10 seconds: Position error ≈ 0.5 meters\n- After 60 seconds: Position error ≈ 18 meters\n\n**Gyroscope drift**:\n- Bias: 0.1°/s\n- After 60 seconds: Heading error ≈ 6°\n\n**Solution**: Fuse with GPS (Kalman Filter) to bound drift.\n\n---\n\n### IMU-GPS Fusion\n\n**Complementary strengths**:\n- **GPS**: Low-rate (1-10 Hz), bounded error, global\n- **IMU**: High-rate (100-1000 Hz), drift, local\n\n**Extended Kalman Filter (EKF)**:\n- **Prediction**: Use IMU to propagate state at high rate\n- **Update**: Use GPS to correct drift (when available)\n\n**State vector**:\n$$\\mathbf{x} = [x, y, v_x, v_y, \\theta, \\omega, a_x, a_y, b_{gyro}, b_{acc}]^T$$\n\nIncludes position, velocity, orientation, angular velocity, acceleration, and sensor biases.\n\n---\n\n### IMU Types and Performance\n\n| IMU Grade | Gyro Bias | Acc Bias | Cost | Application |\n|-----------|-----------|----------|------|-------------|\n| **Consumer** | 10-100°/hr | 0.01 m/s² | $10-100 | Smartphones, drones |\n| **Tactical** | 1-10°/hr | 0.001 m/s² | $1k-10k | Automotive, robotics |\n| **Navigation** | <1°/hr | <0.0001 m/s² | $10k-100k | Aircraft, submarines |\n\n**Automotive AVs** typically use **Tactical-grade** IMUs (e.g., Xsens, VectorNav, Novatel).\n\n---\n\n### Wheel Odometry\n\n**Alternative/complement to IMU**: Measure wheel rotations.\n\n**Advantages**:\n- ✅ No drift in straight-line motion (on flat ground)\n- ✅ Accurate speed measurement\n- ✅ Low cost (use existing wheel speed sensors)\n\n**Disadvantages**:\n- ❌ Wheel slip (rain, ice, acceleration)\n- ❌ Tire wear affects calibration\n- ❌ Doesn't measure lateral motion\n\n**Fusion**: Combine GPS + IMU + Wheel Odometry for best results.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Exercises\n\n### Exercise 1: Particle Filter for Kidnapped Robot Problem\n\nImplement a particle filter that can recover when the robot is \"kidnapped\" (teleported to an unknown location).\n\n**Tasks:**\n1. Modify the particle filter to occasionally inject random particles\n2. Simulate kidnapping the robot at step 5\n3. Show how the filter recovers\n4. Compare recovery time with different numbers of random particles injected\n\n**Hint:** Add uniform random particles when effective sample size drops below a threshold."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Exercise 3 - Starter code\n\ndef create_multi_lane_map():\n    \"\"\"Create HD map with 3 lanes\"\"\"\n    # TODO: Define lane centerlines\n    # Lane 1: y = 0\n    # Lane 2: y = 3.5\n    # Lane 3: y = 7.0\n    pass\n\ndef lane_level_localization():\n    \"\"\"Determine which lane the vehicle is in\"\"\"\n    # TODO:\n    # 1. Get GPS position (noisy)\n    # 2. Detect lane markings (lateral offset)\n    # 3. Fuse to determine lane ID\n    # 4. Track lane changes\n    pass\n\n# Your implementation here"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## References and Additional Resources\n\n### Core Textbooks\n\n1. **Probabilistic Robotics** by Thrun, Burgard, and Fox (2005)\n   - Chapter 8: Mobile Robot Localization (Monte Carlo Localization)\n   - Chapter 10: SLAM\n   - Chapter 13: FastSLAM\n\n2. **State Estimation for Robotics** by Barfoot (2017)\n   - Chapters on SLAM and mapping\n\n3. **Autonomous Driving** by Yurtsever et al. (2020)\n   - Survey on localization methods for autonomous vehicles\n\n### Key Papers\n\n1. **Monte Carlo Localization**\n   - Dellaert et al. (1999) - \"Monte Carlo Localization for Mobile Robots\"\n   - Fox et al. (1999) - \"Monte Carlo Localization: Efficient Position Estimation\"\n\n2. **SLAM**\n   - Dissanayake et al. (2001) - \"A Solution to the SLAM Problem\"\n   - Durrant-Whyte & Bailey (2006) - \"Simultaneous Localization and Mapping: Part I & II\"\n   - Cadena et al. (2016) - \"Past, Present, and Future of SLAM\" (Survey)\n\n3. **Visual SLAM**\n   - Mur-Artal & Tardós (2017) - \"ORB-SLAM2: an Open-Source SLAM System\"\n   - Campos et al. (2021) - \"ORB-SLAM3\"\n\n4. **HD Maps**\n   - Seif & Hu (2016) - \"Autonomous Driving in the iCity - HD Maps as a Key Challenge\"\n   - Liu et al. (2020) - \"High Definition Maps for Autonomous Driving\"\n\n### Software & Libraries\n\n1. **SLAM Libraries**\n   - **g2o**: General Graph Optimization - https://github.com/RainerKuemmerle/g2o\n   - **GTSAM**: Georgia Tech Smoothing and Mapping - https://github.com/borglab/gtsam\n   - **ORB-SLAM3**: Visual SLAM - https://github.com/UZ-SLAMLab/ORB_SLAM3\n   - **Cartographer**: Google's SLAM - https://github.com/cartographer-project/cartographer\n\n2. **Particle Filter**\n   - **particle-filter-tutorial**: Python implementations\n   - ROS packages: amcl (Adaptive Monte Carlo Localization)\n\n3. **HD Maps**\n   - **Lanelet2**: https://github.com/fzi-forschungszentrum-informatik/Lanelet2\n   - **OpenDRIVE**: Industry standard format\n   - **Apollo HD Map**: Baidu's open-source HD map module\n\n### Online Resources\n\n1. **Cyrill Stachniss YouTube Lectures**\n   - Mobile Sensing and Robotics course\n   - Excellent SLAM and localization lectures\n\n2. **Self-Driving Cars Specialization (Coursera)**\n   - University of Toronto\n   - Modules on localization and mapping\n\n3. **Udacity Self-Driving Car Nanodegree**\n   - Particle filter project\n   - Kidnapped vehicle project\n\n### Datasets\n\n1. **KITTI Dataset**: Autonomous driving benchmark\n2. **nuScenes**: Full sensor suite with HD maps\n3. **Waymo Open Dataset**: Large-scale AV dataset\n4. **Oxford RobotCar**: Long-term autonomy dataset\n\n### Industry Standards\n\n- **ISO 19157**: Geographic Information - Data Quality\n- **OpenDRIVE**: Road network description\n- **NDS (Navigation Data Standard)**: Automotive navigation\n- **Lanelet/Lanelet2**: Autonomous driving maps\n\n### Applications in Autonomous Vehicles\n\n1. **Localization Stack**\n   - GPS/GNSS: Coarse global position\n   - IMU: High-rate pose updates\n   - Wheel odometry: Dead reckoning\n   - LIDAR: Map matching and obstacle detection\n   - Camera: Lane detection and visual odometry\n\n2. **Map Update Strategies**\n   - Crowdsourced mapping (fleet learning)\n   - Real-time dynamic layer updates\n   - Cloud-based map management\n\n3. **Challenges**\n   - Urban canyons (GPS multipath)\n   - Tunnels (no GPS)\n   - Dynamic environments\n   - Map scalability and storage\n\n---\n\n## Summary\n\nThis notebook covered localization and mapping for autonomous vehicles:\n\n**Key Concepts:**\n- GPS/GNSS principles and error sources\n- Particle Filters for global localization\n- SLAM (Simultaneous Localization and Mapping)\n- HD Maps for precise localization\n\n**Practical Skills:**\n- Implementing particle filters with resampling\n- Building EKF-SLAM systems\n- Map-matching for improved accuracy\n- Multi-sensor fusion strategies\n\n**Next Steps:**\n1. Implement a full sensor fusion system\n2. Explore Graph-SLAM and optimization-based approaches\n3. Study Visual-Inertial Odometry (VIO)\n4. Learn about semantic SLAM and dynamic environments"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}