{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6: Probabilistic State Estimation\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "- Modeling Uncertainty; Bayes Filter fundamentals; Introduction to Kalman Filters (Linear, Extended, Unscented) for tracking\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Understand the key concepts\n",
    "2. Implement algorithms\n",
    "3. Apply techniques to real-world problems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Additional imports as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Modeling Uncertainty\n\nIn autonomous systems, we never have perfect information about the world. Sensors are noisy, models are approximate, and the environment is unpredictable. Probabilistic state estimation provides a principled framework for reasoning under uncertainty.\n\n### Sources of Uncertainty\n\n1. **Measurement Noise**: Sensors provide imperfect observations\n   - GPS accuracy: ±5-10 meters\n   - LIDAR noise: ±2-3 cm\n   - Camera pixel uncertainty\n\n2. **Process Noise**: System dynamics are not perfectly modeled\n   - Wind effects on vehicle motion\n   - Tire slip\n   - Unmodeled disturbances\n\n3. **Model Uncertainty**: Simplified representations of reality\n   - Linearization errors\n   - Parameter uncertainty\n\n### Probability Distributions\n\nWe represent uncertainty using probability distributions:\n\n**Gaussian (Normal) Distribution:**\n$$p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$\n\n- Mean $\\mu$: Expected value\n- Variance $\\sigma^2$: Uncertainty\n\n**Multivariate Gaussian:**\n$$p(\\mathbf{x}) = \\frac{1}{\\sqrt{(2\\pi)^n|\\boldsymbol{\\Sigma}|}} e^{-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^T\\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})}$$\n\n- Mean vector $\\boldsymbol{\\mu}$\n- Covariance matrix $\\boldsymbol{\\Sigma}$ (captures correlations)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Unscented Kalman Filter Implementation\n\nclass UnscentedKalmanFilter:\n    def __init__(self, n_states, initial_state, initial_cov, process_noise, measurement_noise,\n                 alpha=1e-3, beta=2, kappa=0):\n        \"\"\"\n        UKF implementation\n        \n        Parameters:\n        - n_states: dimension of state vector\n        - alpha: spread of sigma points (typically 1e-3 to 1)\n        - beta: incorporates prior knowledge (2 is optimal for Gaussian)\n        - kappa: secondary scaling parameter (typically 0 or 3-n)\n        \"\"\"\n        self.n = n_states\n        self.x = initial_state\n        self.P = initial_cov\n        self.Q = process_noise\n        self.R = measurement_noise\n        \n        # UKF parameters\n        self.alpha = alpha\n        self.beta = beta\n        self.kappa = kappa\n        \n        self.lambda_ = alpha**2 * (n_states + kappa) - n_states\n        \n        # Weights for mean and covariance\n        self.Wm = np.zeros(2 * n_states + 1)\n        self.Wc = np.zeros(2 * n_states + 1)\n        \n        self.Wm[0] = self.lambda_ / (n_states + self.lambda_)\n        self.Wc[0] = self.lambda_ / (n_states + self.lambda_) + (1 - alpha**2 + beta)\n        \n        for i in range(1, 2 * n_states + 1):\n            self.Wm[i] = 1.0 / (2.0 * (n_states + self.lambda_))\n            self.Wc[i] = self.Wm[i]\n    \n    def generate_sigma_points(self, x, P):\n        \"\"\"Generate sigma points around x with covariance P\"\"\"\n        n = len(x)\n        sigma_points = np.zeros((2 * n + 1, n))\n        \n        # Center point\n        sigma_points[0] = x\n        \n        # Matrix square root using Cholesky decomposition\n        try:\n            U = np.linalg.cholesky((n + self.lambda_) * P)\n        except np.linalg.LinAlgError:\n            # If Cholesky fails, use eigenvalue decomposition\n            eigvals, eigvecs = np.linalg.eigh(P)\n            eigvals = np.maximum(eigvals, 0)  # Ensure positive\n            U = eigvecs @ np.diag(np.sqrt((n + self.lambda_) * eigvals))\n        \n        # Positive sigma points\n        for i in range(n):\n            sigma_points[i + 1] = x + U[:, i]\n        \n        # Negative sigma points\n        for i in range(n):\n            sigma_points[n + i + 1] = x - U[:, i]\n        \n        return sigma_points\n    \n    def predict(self, dt, f):\n        \"\"\"\n        Prediction step\n        f: state transition function f(x, dt) -> x_new\n        \"\"\"\n        # Generate sigma points\n        sigma_points = self.generate_sigma_points(self.x, self.P)\n        \n        # Propagate sigma points through motion model\n        n = len(self.x)\n        sigma_points_pred = np.zeros((2 * n + 1, n))\n        \n        for i in range(2 * n + 1):\n            sigma_points_pred[i] = f(sigma_points[i], dt)\n        \n        # Compute predicted mean\n        self.x = np.sum(self.Wm[:, np.newaxis] * sigma_points_pred, axis=0)\n        \n        # Compute predicted covariance\n        self.P = np.zeros((n, n))\n        for i in range(2 * n + 1):\n            diff = sigma_points_pred[i] - self.x\n            self.P += self.Wc[i] * np.outer(diff, diff)\n        \n        self.P += self.Q\n    \n    def update(self, z, h):\n        \"\"\"\n        Update step\n        z: measurement vector\n        h: measurement function h(x) -> z_pred\n        \"\"\"\n        n = len(self.x)\n        m = len(z)\n        \n        # Generate sigma points from predicted state\n        sigma_points = self.generate_sigma_points(self.x, self.P)\n        \n        # Propagate sigma points through measurement model\n        sigma_meas = np.zeros((2 * n + 1, m))\n        for i in range(2 * n + 1):\n            sigma_meas[i] = h(sigma_points[i])\n        \n        # Predicted measurement\n        z_pred = np.sum(self.Wm[:, np.newaxis] * sigma_meas, axis=0)\n        \n        # Innovation covariance\n        S = np.zeros((m, m))\n        for i in range(2 * n + 1):\n            diff = sigma_meas[i] - z_pred\n            S += self.Wc[i] * np.outer(diff, diff)\n        S += self.R\n        \n        # Cross-correlation\n        Pxz = np.zeros((n, m))\n        for i in range(2 * n + 1):\n            dx = sigma_points[i] - self.x\n            dz = sigma_meas[i] - z_pred\n            Pxz += self.Wc[i] * np.outer(dx, dz)\n        \n        # Kalman gain\n        K = Pxz @ np.linalg.inv(S)\n        \n        # State update\n        self.x = self.x + K @ (z - z_pred)\n        \n        # Covariance update\n        self.P = self.P - K @ S @ K.T\n\n\n# Comparison: UKF vs EKF on highly nonlinear system\ndef compare_ukf_ekf():\n    np.random.seed(42)\n    \n    # State transition (nonlinear)\n    def f(x, dt):\n        \"\"\"Constant turn rate and velocity model\"\"\"\n        px, py, v, theta, omega = x\n        if abs(omega) < 1e-6:  # Straight line motion\n            return np.array([\n                px + v * np.cos(theta) * dt,\n                py + v * np.sin(theta) * dt,\n                v,\n                theta,\n                omega\n            ])\n        else:  # Curved motion\n            return np.array([\n                px + v / omega * (np.sin(theta + omega * dt) - np.sin(theta)),\n                py + v / omega * (-np.cos(theta + omega * dt) + np.cos(theta)),\n                v,\n                theta + omega * dt,\n                omega\n            ])\n    \n    # Measurement model (range-bearing)\n    def h(x):\n        px, py, _, _, _ = x\n        r = np.sqrt(px**2 + py**2)\n        bearing = np.arctan2(py, px)\n        return np.array([r, bearing])\n    \n    # Simulation\n    dt = 0.1\n    num_steps = 100\n    \n    # True initial state: [px, py, v, theta, omega]\n    x_true = np.array([0.0, 0.0, 5.0, np.pi/4, 0.1])  # Turning motion\n    \n    true_states = []\n    measurements = []\n    \n    for t in range(num_steps):\n        x_true = f(x_true, dt)\n        true_states.append(x_true.copy())\n        \n        # Noisy measurement\n        z_true = h(x_true)\n        z_meas = z_true + np.array([np.random.randn() * 2.0, np.random.randn() * 0.1])\n        measurements.append(z_meas)\n    \n    true_states = np.array(true_states)\n    measurements = np.array(measurements)\n    \n    # Initialize UKF\n    x0 = np.array([0.0, 0.0, 4.0, np.pi/4, 0.0])  # Initial guess\n    P0 = np.diag([5.0, 5.0, 2.0, 0.5, 0.2])\n    Q = np.diag([0.1, 0.1, 0.1, 0.01, 0.01])\n    R = np.diag([4.0, 0.01])\n    \n    ukf = UnscentedKalmanFilter(5, x0.copy(), P0.copy(), Q, R)\n    \n    ukf_estimates = []\n    \n    for i in range(num_steps):\n        ukf.predict(dt, f)\n        ukf.update(measurements[i], h)\n        ukf_estimates.append(ukf.x.copy())\n    \n    ukf_estimates = np.array(ukf_estimates)\n    \n    # Visualization\n    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n    \n    # Trajectory\n    axes[0].plot(true_states[:, 0], true_states[:, 1], 'g-', label='True', linewidth=2)\n    axes[0].plot(ukf_estimates[:, 0], ukf_estimates[:, 1], 'b-', label='UKF', linewidth=2)\n    axes[0].plot(0, 0, 'r*', markersize=15, label='Sensor')\n    axes[0].set_xlabel('X Position')\n    axes[0].set_ylabel('Y Position')\n    axes[0].set_title('UKF Tracking (Nonlinear Turning Motion)')\n    axes[0].legend()\n    axes[0].grid(True)\n    axes[0].axis('equal')\n    \n    # Position error\n    position_error = np.sqrt((ukf_estimates[:, 0] - true_states[:, 0])**2 + \n                            (ukf_estimates[:, 1] - true_states[:, 1])**2)\n    time = np.arange(num_steps) * dt\n    \n    axes[1].plot(time, position_error, 'b-', linewidth=2)\n    axes[1].set_xlabel('Time (s)')\n    axes[1].set_ylabel('Position Error (m)')\n    axes[1].set_title('UKF Position Error')\n    axes[1].grid(True)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"Mean Position Error: {np.mean(position_error):.2f} m\")\n    print(f\"Max Position Error: {np.max(position_error):.2f} m\")\n\ncompare_ukf_ekf()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Exercises\n\n### Exercise 1: 1D Kalman Filter for Temperature Tracking\n\nImplement a 1D Kalman filter to estimate room temperature from noisy sensor readings.\n\n**Given:**\n- True temperature: 20°C with small random walk (±0.1°C per step)\n- Sensor noise: ±1.5°C (standard deviation)\n- 100 time steps\n\n**Tasks:**\n1. Implement the 1D Kalman filter\n2. Plot true temperature, measurements, and estimates\n3. Calculate the mean squared error\n4. Experiment with different process and measurement noise values"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Exercise 3: This is left as a challenge for the student\n# Hint: Reuse the implementations from sections 3-5\n# Try different turning rates (omega values) to vary nonlinearity\n\n# Here's a template to get started:\n\ndef compare_all_filters():\n    \"\"\"\n    Compare Linear KF (will perform poorly), EKF, and UKF\n    on a turning vehicle scenario\n    \"\"\"\n    # TODO: Implement comparison\n    # 1. Set up nonlinear motion model (constant turn rate)\n    # 2. Initialize all three filters with same parameters\n    # 3. Run them on the same measurement sequence\n    # 4. Compare errors and computation time\n    # 5. Visualize results\n    \n    pass  # Your implementation here\n\n# Uncomment to run:\n# compare_all_filters()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## References and Additional Resources\n\n### Core Textbooks\n\n1. **Probabilistic Robotics** by Thrun, Burgard, and Fox (2005)\n   - The definitive reference for probabilistic state estimation\n   - Chapters 2-3: Recursive state estimation and Bayes filters\n   - Chapter 3.2: Kalman Filter\n   - Chapter 3.3: Extended Kalman Filter\n   - Chapter 3.4: Unscented Kalman Filter\n\n2. **Optimal State Estimation** by Simon (2006)\n   - Comprehensive treatment of Kalman filtering\n   - Practical implementation considerations\n\n3. **State Estimation for Robotics** by Barfoot (2017)\n   - Modern perspective with robotics applications\n   - Available online: http://asrl.utias.utoronto.ca/~tdb/bib/barfoot_ser17.pdf\n\n### Key Papers\n\n1. **Kalman, R. E. (1960)** - \"A New Approach to Linear Filtering and Prediction Problems\"\n   - Original Kalman filter paper\n   - Transactions of the ASME–Journal of Basic Engineering\n\n2. **Julier, S. J., & Uhlmann, J. K. (1997)** - \"New extension of the Kalman filter to nonlinear systems\"\n   - Introduced the Unscented Kalman Filter\n   - SPIE 3068, Signal Processing, Sensor Fusion, and Target Recognition VI\n\n### Online Resources\n\n1. **Kalman Filter Tutorial by Greg Welch and Gary Bishop**\n   - https://www.cs.unc.edu/~welch/kalman/\n   - Excellent introduction with practical examples\n\n2. **Roger Labbe's Kalman Filter Book (Jupyter Notebooks)**\n   - https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python\n   - Interactive Python implementations\n\n3. **Udacity Self-Driving Car Nanodegree**\n   - Extended Kalman Filter project\n   - Sensor fusion with LIDAR and RADAR\n\n### Software Libraries\n\n1. **FilterPy** (Python)\n   - pip install filterpy\n   - Kalman filter implementations\n\n2. **PyKalman** (Python)\n   - pip install pykalman\n   - EM algorithm for parameter estimation\n\n3. **Robot Operating System (ROS)**\n   - robot_localization package\n   - Production-ready EKF/UKF implementations\n\n### Applications in Autonomous Vehicles\n\n1. **Localization**: GPS/IMU fusion for position estimation\n2. **Object Tracking**: Multi-object tracking with RADAR/LIDAR/Camera\n3. **SLAM**: Simultaneous Localization and Mapping\n4. **Sensor Calibration**: Estimating sensor biases and drift\n\n### Related Topics to Explore\n\n1. **Particle Filters**: Non-parametric Bayes filter for multimodal distributions\n2. **Information Filter**: Inverse covariance form of Kalman filter\n3. **Kalman Smoother**: Batch processing for improved estimates\n4. **Multi-Hypothesis Tracking**: Handling data association uncertainty\n5. **Adaptive Filtering**: Online estimation of Q and R matrices\n\n### Visualization Tools\n\n- **Matplotlib** (used in this notebook)\n- **Plotly**: Interactive visualizations\n- **RViz**: Real-time robotics visualization\n\n---\n\n## Summary\n\nThis notebook covered the fundamentals of probabilistic state estimation:\n\n**Key Concepts:**\n- Uncertainty representation with Gaussian distributions\n- Bayes filter framework (predict + update)\n- Kalman Filter for linear systems\n- Extended Kalman Filter for nonlinear systems (Jacobian linearization)\n- Unscented Kalman Filter for highly nonlinear systems (sigma points)\n\n**Practical Skills:**\n- Implementing filters from scratch\n- Tuning process and measurement noise\n- Sensor fusion techniques\n- Performance evaluation\n\n**Next Steps:**\n1. Explore the HTML visualizations in this repository ([kalman_ball_chase.html](kalman_ball_chase.html))\n2. Implement a real-world application (e.g., GPS/IMU fusion)\n3. Study Particle Filters for non-Gaussian distributions\n4. Learn about SLAM and its relation to state estimation"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}