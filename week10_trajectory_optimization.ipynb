{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10: Trajectory Optimization\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "- Cost Functions (smoothness, speed, safety); Model Predictive Control (MPC) for planning and control integration; Real-time constraints\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Understand the key concepts\n",
    "2. Implement algorithms\n",
    "3. Apply techniques to real-world problems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle, Circle, Polygon, FancyArrowPatch\nfrom matplotlib.animation import FuncAnimation\nfrom scipy.optimize import minimize\nfrom scipy.interpolate import CubicSpline\n\n# Set random seed for reproducibility\nnp.random.seed(42)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Trajectory Optimization Fundamentals\n\nTrajectory optimization finds the **best** trajectory that satisfies constraints while minimizing a cost function.\n\n### Trajectory vs. Path\n\n- **Path**: Geometric curve in space (no time information)\n  - Example: $(x(s), y(s))$ where $s \\in [0, 1]$\n  \n- **Trajectory**: Path with timing information\n  - Example: $(x(t), y(t), v(t))$ where $t$ is time\n\n### Optimization Problem Formulation\n\n**Decision Variables:** Trajectory parameters $\\mathbf{z} = [x_0, x_1, \\ldots, x_N, u_0, u_1, \\ldots, u_{N-1}]$\n\n**Minimize:**\n$$J(\\mathbf{z}) = \\phi(x_N) + \\sum_{k=0}^{N-1} L(x_k, u_k)$$\n\n**Subject to:**\n- **Dynamics:** $x_{k+1} = f(x_k, u_k)$\n- **Initial conditions:** $x_0 = x_{init}$\n- **Goal constraints:** $x_N \\in \\mathcal{X}_{goal}$\n- **State constraints:** $x_k \\in \\mathcal{X}_{safe}$\n- **Control constraints:** $u_k \\in \\mathcal{U}$\n\nWhere:\n- $x_k$: State at time step $k$ (position, velocity, heading)\n- $u_k$: Control input (steering, acceleration)\n- $\\phi(x_N)$: Terminal cost\n- $L(x_k, u_k)$: Stage cost\n\n### Cost Function Components\n\n**1. Smoothness:**\n$$J_{smooth} = \\int_0^T \\left( \\left(\\frac{d^2x}{dt^2}\\right)^2 + \\left(\\frac{d^2y}{dt^2}\\right)^2 \\right) dt$$\nPenalizes high accelerations (jerk minimization)\n\n**2. Speed:**\n$$J_{speed} = \\int_0^T (v_{ref} - v(t))^2 dt$$\nTracks desired speed\n\n**3. Safety (Obstacle Avoidance):**\n$$J_{safety} = \\sum_{obstacles} \\max(0, d_{safe} - d(x, obs))^2$$\nPenalizes being too close to obstacles\n\n**4. Control Effort:**\n$$J_{control} = \\int_0^T (u(t)^T R u(t)) dt$$\nMinimizes steering and acceleration inputs\n\n**Total Cost:**\n$$J = w_1 J_{smooth} + w_2 J_{speed} + w_3 J_{safety} + w_4 J_{control}$$\n\n---\n\n## 2. Polynomial Trajectory Generation\n\nPolynomial trajectories provide smooth, differentiable paths ideal for robotic motion.\n\n### Quintic (5th Order) Polynomial\n\nFor a 1D trajectory from $(p_0, v_0, a_0)$ to $(p_f, v_f, a_f)$ over time $T$:\n\n$$p(t) = c_0 + c_1 t + c_2 t^2 + c_3 t^3 + c_4 t^4 + c_5 t^5$$\n\n**Boundary Conditions:**\n- $p(0) = p_0, \\quad \\dot{p}(0) = v_0, \\quad \\ddot{p}(0) = a_0$\n- $p(T) = p_f, \\quad \\dot{p}(T) = v_f, \\quad \\ddot{p}(T) = a_f$\n\nThis gives us 6 equations for 6 unknowns $(c_0, \\ldots, c_5)$.\n\n**Matrix Form:**\n$$\\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 2 & 0 & 0 & 0 \\\\ 1 & T & T^2 & T^3 & T^4 & T^5 \\\\ 0 & 1 & 2T & 3T^2 & 4T^3 & 5T^4 \\\\ 0 & 0 & 2 & 6T & 12T^2 & 20T^3 \\end{bmatrix} \\begin{bmatrix} c_0 \\\\ c_1 \\\\ c_2 \\\\ c_3 \\\\ c_4 \\\\ c_5 \\end{bmatrix} = \\begin{bmatrix} p_0 \\\\ v_0 \\\\ a_0 \\\\ p_f \\\\ v_f \\\\ a_f \\end{bmatrix}$$\n\n**Advantages:**\n- Smooth up to 2nd derivative (continuous acceleration)\n- Exact boundary condition satisfaction\n- Analytically computable jerk and snap\n\n**Applications:**\n- Robotic manipulator motion\n- Drone waypoint navigation\n- Lane change maneuvers"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Quintic Polynomial Trajectory Generator\n\nclass QuinticPolynomial:\n    \"\"\"Quintic (5th order) polynomial for smooth 1D trajectory.\"\"\"\n    \n    def __init__(self, p0, v0, a0, pf, vf, af, T):\n        \"\"\"\n        Generate quintic polynomial trajectory.\n        \n        Parameters:\n        - p0, v0, a0: Initial position, velocity, acceleration\n        - pf, vf, af: Final position, velocity, acceleration\n        - T: Duration\n        \"\"\"\n        # Coefficient matrix\n        A = np.array([\n            [1, 0, 0, 0, 0, 0],\n            [0, 1, 0, 0, 0, 0],\n            [0, 0, 2, 0, 0, 0],\n            [1, T, T**2, T**3, T**4, T**5],\n            [0, 1, 2*T, 3*T**2, 4*T**3, 5*T**4],\n            [0, 0, 2, 6*T, 12*T**2, 20*T**3]\n        ])\n        \n        # Boundary conditions\n        b = np.array([p0, v0, a0, pf, vf, af])\n        \n        # Solve for coefficients\n        self.coeffs = np.linalg.solve(A, b)\n        self.T = T\n    \n    def position(self, t):\n        \"\"\"Compute position at time t.\"\"\"\n        c = self.coeffs\n        return c[0] + c[1]*t + c[2]*t**2 + c[3]*t**3 + c[4]*t**4 + c[5]*t**5\n    \n    def velocity(self, t):\n        \"\"\"Compute velocity at time t.\"\"\"\n        c = self.coeffs\n        return c[1] + 2*c[2]*t + 3*c[3]*t**2 + 4*c[4]*t**3 + 5*c[5]*t**4\n    \n    def acceleration(self, t):\n        \"\"\"Compute acceleration at time t.\"\"\"\n        c = self.coeffs\n        return 2*c[2] + 6*c[3]*t + 12*c[4]*t**2 + 20*c[5]*t**3\n    \n    def jerk(self, t):\n        \"\"\"Compute jerk (derivative of acceleration) at time t.\"\"\"\n        c = self.coeffs\n        return 6*c[3] + 24*c[4]*t + 60*c[5]*t**2\n\n\ndef demonstrate_quintic_trajectory():\n    \"\"\"Demonstrate quintic polynomial trajectory for lane change.\"\"\"\n    \n    # Lane change scenario\n    # Start: lane center at y=0, moving forward at 20 m/s\n    # End: lane center at y=3.5, moving forward at 20 m/s\n    # Duration: 3 seconds\n    \n    # Lateral motion (y-direction)\n    y0, v_y0, a_y0 = 0.0, 0.0, 0.0  # Start in left lane\n    yf, v_yf, a_yf = 3.5, 0.0, 0.0  # End in right lane\n    T = 3.0\n    \n    quintic_y = QuinticPolynomial(y0, v_y0, a_y0, yf, v_yf, a_yf, T)\n    \n    # Longitudinal motion (x-direction) - constant velocity\n    v_x = 20.0  # m/s\n    \n    # Generate trajectory\n    t = np.linspace(0, T, 100)\n    y_traj = np.array([quintic_y.position(ti) for ti in t])\n    vy_traj = np.array([quintic_y.velocity(ti) for ti in t])\n    ay_traj = np.array([quintic_y.acceleration(ti) for ti in t])\n    jerk_traj = np.array([quintic_y.jerk(ti) for ti in t])\n    \n    x_traj = v_x * t  # Constant velocity in x\n    \n    # Visualization\n    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n    \n    # 1. 2D Trajectory (top view)\n    ax1 = axes[0, 0]\n    ax1.plot(x_traj, y_traj, 'b-', linewidth=3, label='Vehicle Path')\n    ax1.axhline(y=0, color='gray', linestyle='--', alpha=0.5, linewidth=2, label='Left Lane')\n    ax1.axhline(y=3.5, color='gray', linestyle='--', alpha=0.5, linewidth=2, label='Right Lane')\n    ax1.plot(x_traj[0], y_traj[0], 'go', markersize=12, label='Start')\n    ax1.plot(x_traj[-1], y_traj[-1], 'ro', markersize=12, label='End')\n    \n    # Draw vehicle at several positions\n    for i in [0, 25, 50, 75, 99]:\n        vehicle_length, vehicle_width = 4.5, 2.0\n        rect = Rectangle((x_traj[i] - vehicle_length/2, y_traj[i] - vehicle_width/2),\n                        vehicle_length, vehicle_width, \n                        fill=False, edgecolor='blue', alpha=0.3)\n        ax1.add_patch(rect)\n    \n    ax1.set_xlabel('Longitudinal Position X (m)', fontsize=11)\n    ax1.set_ylabel('Lateral Position Y (m)', fontsize=11)\n    ax1.set_title('Lane Change Trajectory (Top View)', fontsize=12, fontweight='bold')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    ax1.set_ylim([-1, 5])\n    \n    # 2. Lateral Position over Time\n    ax2 = axes[0, 1]\n    ax2.plot(t, y_traj, 'b-', linewidth=2)\n    ax2.axhline(y=0, color='g', linestyle='--', alpha=0.5, label='Left Lane')\n    ax2.axhline(y=3.5, color='r', linestyle='--', alpha=0.5, label='Right Lane')\n    ax2.set_xlabel('Time (s)', fontsize=11)\n    ax2.set_ylabel('Lateral Position Y (m)', fontsize=11)\n    ax2.set_title('Lateral Position Profile', fontsize=12, fontweight='bold')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    # 3. Lateral Velocity\n    ax3 = axes[0, 2]\n    ax3.plot(t, vy_traj, 'g-', linewidth=2)\n    ax3.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n    ax3.set_xlabel('Time (s)', fontsize=11)\n    ax3.set_ylabel('Lateral Velocity (m/s)', fontsize=11)\n    ax3.set_title('Lateral Velocity Profile', fontsize=12, fontweight='bold')\n    ax3.grid(True, alpha=0.3)\n    \n    # 4. Lateral Acceleration\n    ax4 = axes[1, 0]\n    ax4.plot(t, ay_traj, 'r-', linewidth=2)\n    ax4.axhline(y=2.0, color='orange', linestyle='--', alpha=0.7, label='Comfort Limit (±2 m/s²)')\n    ax4.axhline(y=-2.0, color='orange', linestyle='--', alpha=0.7)\n    ax4.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n    ax4.set_xlabel('Time (s)', fontsize=11)\n    ax4.set_ylabel('Lateral Acceleration (m/s²)', fontsize=11)\n    ax4.set_title('Lateral Acceleration Profile', fontsize=12, fontweight='bold')\n    ax4.legend()\n    ax4.grid(True, alpha=0.3)\n    \n    # 5. Jerk\n    ax5 = axes[1, 1]\n    ax5.plot(t, jerk_traj, 'm-', linewidth=2)\n    ax5.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n    ax5.set_xlabel('Time (s)', fontsize=11)\n    ax5.set_ylabel('Jerk (m/s³)', fontsize=11)\n    ax5.set_title('Jerk Profile (Smoothness Measure)', fontsize=12, fontweight='bold')\n    ax5.grid(True, alpha=0.3)\n    \n    # 6. Metrics Summary\n    ax6 = axes[1, 2]\n    ax6.axis('off')\n    \n    max_vy = np.max(np.abs(vy_traj))\n    max_ay = np.max(np.abs(ay_traj))\n    max_jerk = np.max(np.abs(jerk_traj))\n    \n    metrics_text = f\"\"\"\n    QUINTIC TRAJECTORY METRICS\n    {'='*40}\n    \n    Duration:              {T:.2f} s\n    Lateral Displacement:  {yf - y0:.2f} m\n    \n    Max Lateral Velocity:  {max_vy:.3f} m/s\n    Max Lateral Accel:     {max_ay:.3f} m/s²\n    Max Jerk:              {max_jerk:.3f} m/s³\n    \n    Boundary Conditions:\n      Start: y={y0:.1f}m, v={v_y0:.1f}m/s, a={a_y0:.1f}m/s²\n      End:   y={yf:.1f}m, v={v_yf:.1f}m/s, a={a_yf:.1f}m/s²\n    \n    Comfort Check:\n      Accel < 2.0 m/s²:    {'✓ PASS' if max_ay < 2.0 else '✗ FAIL'}\n      Smooth (continuous): ✓ PASS\n    \n    Polynomial Coefficients:\n    \"\"\"\n    \n    for i, c in enumerate(quintic_y.coeffs):\n        metrics_text += f\"  c{i} = {c:10.6f}\\n\"\n    \n    ax6.text(0.1, 0.95, metrics_text, transform=ax6.transAxes,\n             fontsize=10, verticalalignment='top', family='monospace',\n             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"=\"*70)\n    print(\"QUINTIC POLYNOMIAL TRAJECTORY GENERATION\")\n    print(\"=\"*70)\n    print(f\"Scenario: Lane change from y=0m to y=3.5m in {T}s\")\n    print(f\"Max lateral velocity:     {max_vy:.3f} m/s\")\n    print(f\"Max lateral acceleration: {max_ay:.3f} m/s²\")\n    print(f\"Max jerk:                 {max_jerk:.3f} m/s³\")\n    print(f\"Comfort limit (2 m/s²):   {'SATISFIED' if max_ay < 2.0 else 'VIOLATED'}\")\n    print(\"=\"*70)\n\ndemonstrate_quintic_trajectory()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Model Predictive Control with Obstacle Avoidance\n\nclass ObstacleAvoidanceMPC:\n    \"\"\"MPC with soft obstacle avoidance constraints.\"\"\"\n    \n    def __init__(self, horizon=15, dt=0.1, Q=None, R=None, obstacle_weight=5000.0):\n        \"\"\"\n        Initialize MPC with obstacle avoidance.\n        \n        Parameters:\n        - horizon: Prediction horizon steps\n        - dt: Time step\n        - Q: State cost matrix (4x4)\n        - R: Control cost matrix (2x2)\n        - obstacle_weight: Penalty for approaching obstacles\n        \"\"\"\n        self.N = horizon\n        self.dt = dt\n        \n        # Cost matrices\n        self.Q = Q if Q is not None else np.diag([10.0, 10.0, 1.0, 1.0])  # [x, y, vx, vy]\n        self.R = R if R is not None else np.diag([0.1, 0.1])  # [ax, ay]\n        self.obstacle_weight = obstacle_weight\n        \n        # Control limits\n        self.u_max = np.array([3.0, 3.0])  # Max acceleration (m/s²)\n        self.u_min = -self.u_max\n        \n        # Obstacle parameters\n        self.obstacle_radius = 1.5  # Obstacle radius (m)\n        self.safety_margin = 0.5    # Additional safety buffer (m)\n    \n    def dynamics(self, state, control):\n        \"\"\"2D point mass dynamics.\"\"\"\n        x, y, vx, vy = state\n        ax, ay = control\n        \n        x_next = x + vx * self.dt\n        y_next = y + vy * self.dt\n        vx_next = vx + ax * self.dt\n        vy_next = vy + ay * self.dt\n        \n        return np.array([x_next, y_next, vx_next, vy_next])\n    \n    def obstacle_cost(self, state, obstacles):\n        \"\"\"\n        Compute soft constraint penalty for obstacle proximity.\n        \n        Uses quadratic penalty inside safety zone.\n        \"\"\"\n        x, y = state[0], state[1]\n        penalty = 0.0\n        \n        for obs_x, obs_y in obstacles:\n            dist = np.sqrt((x - obs_x)**2 + (y - obs_y)**2)\n            min_dist = self.obstacle_radius + self.safety_margin\n            \n            if dist < min_dist:\n                # Quadratic penalty that increases as distance decreases\n                penalty += (min_dist - dist)**2\n        \n        return self.obstacle_weight * penalty\n    \n    def cost(self, z, x0, x_ref, obstacles_traj):\n        \"\"\"\n        Total cost function including tracking, control, and obstacle avoidance.\n        \n        z: Flattened control sequence\n        x0: Initial state\n        x_ref: Reference trajectory (N+1 x 4)\n        obstacles_traj: List of obstacle positions at each horizon step\n        \"\"\"\n        controls = z.reshape((self.N, 2))\n        states = [x0]\n        total_cost = 0.0\n        \n        for k in range(self.N):\n            # State tracking cost\n            x_error = states[k] - x_ref[k]\n            total_cost += x_error @ self.Q @ x_error\n            \n            # Control cost\n            u = controls[k]\n            total_cost += u @ self.R @ u\n            \n            # Obstacle avoidance cost\n            if k < len(obstacles_traj):\n                total_cost += self.obstacle_cost(states[k], obstacles_traj[k])\n            \n            # Propagate dynamics\n            x_next = self.dynamics(states[k], u)\n            states.append(x_next)\n        \n        # Terminal cost (higher weight)\n        x_error_final = states[-1] - x_ref[-1]\n        total_cost += x_error_final @ (self.Q * 10) @ x_error_final\n        \n        # Terminal obstacle cost\n        if len(obstacles_traj) > 0:\n            total_cost += self.obstacle_cost(states[-1], obstacles_traj[-1])\n        \n        return total_cost\n    \n    def solve(self, x0, x_ref, obstacles_traj):\n        \"\"\"\n        Solve MPC optimization problem.\n        \n        Returns: Optimal control sequence (N x 2)\n        \"\"\"\n        # Initial guess (zero acceleration)\n        u_init = np.zeros(self.N * 2)\n        \n        # Control bounds\n        bounds = [(self.u_min[i % 2], self.u_max[i % 2]) for i in range(self.N * 2)]\n        \n        # Solve\n        result = minimize(\n            fun=lambda z: self.cost(z, x0, x_ref, obstacles_traj),\n            x0=u_init,\n            method='SLSQP',\n            bounds=bounds,\n            options={'maxiter': 100, 'disp': False, 'ftol': 1e-4}\n        )\n        \n        u_opt = result.x.reshape((self.N, 2))\n        return u_opt\n\n\ndef demonstrate_mpc_obstacle_avoidance():\n    \"\"\"Demonstrate MPC with dynamic obstacle avoidance.\"\"\"\n    \n    # Reference trajectory (straight path to goal)\n    start = np.array([0.0, 0.0, 0.0, 0.0])  # [x, y, vx, vy]\n    goal = np.array([50.0, 0.0, 0.0, 0.0])\n    \n    # Moving obstacles\n    obstacle1_start = np.array([15.0, -2.0])\n    obstacle2_start = np.array([30.0, 2.0])\n    obstacle3_start = np.array([40.0, 0.0])\n    \n    # Obstacle velocities\n    v_obs1 = np.array([0.0, 0.5])   # Moving up\n    v_obs2 = np.array([0.0, -0.3])  # Moving down\n    v_obs3 = np.array([-0.2, 0.0])  # Moving left\n    \n    # Initialize MPC\n    mpc = ObstacleAvoidanceMPC(horizon=15, dt=0.15, obstacle_weight=8000.0)\n    \n    # Simulation\n    x_current = start.copy()\n    num_steps = 80\n    \n    states = [x_current]\n    controls = []\n    obstacle_history = []\n    \n    print(\"Running MPC with obstacle avoidance...\")\n    \n    for step in range(num_steps):\n        # Update obstacle positions\n        obs1_pos = obstacle1_start + v_obs1 * step * mpc.dt\n        obs2_pos = obstacle2_start + v_obs2 * step * mpc.dt\n        obs3_pos = obstacle3_start + v_obs3 * step * mpc.dt\n        \n        current_obstacles = [obs1_pos, obs2_pos, obs3_pos]\n        obstacle_history.append(current_obstacles)\n        \n        # Generate reference trajectory (straight line to goal)\n        x_ref_horizon = []\n        for k in range(mpc.N + 1):\n            alpha = min(1.0, (step + k) / num_steps)\n            x_ref_k = start * (1 - alpha) + goal * alpha\n            x_ref_horizon.append(x_ref_k)\n        x_ref_horizon = np.array(x_ref_horizon)\n        \n        # Predict obstacle positions over horizon\n        obstacles_traj = []\n        for k in range(mpc.N + 1):\n            future_step = step + k\n            obs1_future = obstacle1_start + v_obs1 * future_step * mpc.dt\n            obs2_future = obstacle2_start + v_obs2 * future_step * mpc.dt\n            obs3_future = obstacle3_start + v_obs3 * future_step * mpc.dt\n            obstacles_traj.append([obs1_future, obs2_future, obs3_future])\n        \n        # Solve MPC\n        u_opt = mpc.solve(x_current, x_ref_horizon, obstacles_traj)\n        \n        # Apply first control\n        u_apply = u_opt[0]\n        controls.append(u_apply)\n        \n        # Simulate system\n        x_current = mpc.dynamics(x_current, u_apply)\n        states.append(x_current)\n        \n        if step % 10 == 0:\n            print(f\"  Step {step}/{num_steps} - Position: ({x_current[0]:.1f}, {x_current[1]:.1f})\")\n    \n    states = np.array(states)\n    controls = np.array(controls)\n    \n    # Visualization\n    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n    \n    # 1. Trajectory with obstacles\n    ax1 = axes[0, 0]\n    \n    # Plot vehicle trajectory\n    ax1.plot(states[:, 0], states[:, 1], 'b-', linewidth=3, label='Vehicle Path', zorder=5)\n    ax1.plot(states[0, 0], states[0, 1], 'go', markersize=12, label='Start', zorder=6)\n    ax1.plot(states[-1, 0], states[-1, 1], 'r*', markersize=15, label='End', zorder=6)\n    \n    # Reference path\n    ax1.plot([start[0], goal[0]], [start[1], goal[1]], 'g--', alpha=0.5, linewidth=2, label='Reference')\n    \n    # Plot obstacle trajectories\n    for i, obs_start, v_obs, color in [(0, obstacle1_start, v_obs1, 'red'),\n                                        (1, obstacle2_start, v_obs2, 'orange'),\n                                        (2, obstacle3_start, v_obs3, 'purple')]:\n        obs_traj = [obs_start + v_obs * step * mpc.dt for step in range(num_steps)]\n        obs_traj = np.array(obs_traj)\n        ax1.plot(obs_traj[:, 0], obs_traj[:, 1], '--', color=color, alpha=0.3, linewidth=1)\n        \n        # Plot obstacle at several timesteps\n        for step_idx in [0, num_steps//3, 2*num_steps//3, num_steps-1]:\n            obs_pos = obs_start + v_obs * step_idx * mpc.dt\n            circle = Circle(obs_pos, mpc.obstacle_radius, color=color, alpha=0.2, zorder=1)\n            ax1.add_patch(circle)\n            \n            # Safety margin\n            circle_safe = Circle(obs_pos, mpc.obstacle_radius + mpc.safety_margin, \n                               fill=False, edgecolor=color, linestyle=':', alpha=0.5, zorder=1)\n            ax1.add_patch(circle_safe)\n    \n    ax1.set_xlabel('X Position (m)', fontsize=11)\n    ax1.set_ylabel('Y Position (m)', fontsize=11)\n    ax1.set_title('MPC Obstacle Avoidance Trajectory', fontsize=12, fontweight='bold')\n    ax1.legend(loc='upper left')\n    ax1.grid(True, alpha=0.3)\n    ax1.axis('equal')\n    ax1.set_xlim([-5, 55])\n    ax1.set_ylim([-8, 8])\n    \n    # 2. Distance to closest obstacle over time\n    ax2 = axes[0, 1]\n    time_vec = np.arange(num_steps) * mpc.dt\n    \n    min_distances = []\n    for i, obs_list in enumerate(obstacle_history):\n        distances = [np.linalg.norm(states[i, :2] - obs) for obs in obs_list]\n        min_distances.append(min(distances))\n    \n    ax2.plot(time_vec, min_distances, 'b-', linewidth=2)\n    ax2.axhline(y=mpc.obstacle_radius, color='r', linestyle='--', \n               linewidth=2, label='Obstacle Radius', alpha=0.7)\n    ax2.axhline(y=mpc.obstacle_radius + mpc.safety_margin, color='orange', \n               linestyle='--', linewidth=2, label='Safety Margin', alpha=0.7)\n    ax2.fill_between(time_vec, 0, mpc.obstacle_radius, color='red', alpha=0.1)\n    ax2.set_xlabel('Time (s)', fontsize=11)\n    ax2.set_ylabel('Distance to Closest Obstacle (m)', fontsize=11)\n    ax2.set_title('Safety Distance Monitoring', fontsize=12, fontweight='bold')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    ax2.set_ylim([0, 10])\n    \n    # 3. Y position deviation\n    ax3 = axes[0, 2]\n    ax3.plot(time_vec, states[:num_steps, 1], 'b-', linewidth=2)\n    ax3.axhline(y=0, color='g', linestyle='--', alpha=0.5, label='Reference Y=0')\n    ax3.set_xlabel('Time (s)', fontsize=11)\n    ax3.set_ylabel('Y Position (m)', fontsize=11)\n    ax3.set_title('Lateral Deviation for Avoidance', fontsize=12, fontweight='bold')\n    ax3.legend()\n    ax3.grid(True, alpha=0.3)\n    \n    # 4. Control inputs\n    ax4 = axes[1, 0]\n    ax4.plot(time_vec, controls[:, 0], label='ax (longitudinal)', linewidth=2)\n    ax4.plot(time_vec, controls[:, 1], label='ay (lateral)', linewidth=2)\n    ax4.axhline(mpc.u_max[0], color='r', linestyle='--', alpha=0.5, label='Limits')\n    ax4.axhline(mpc.u_min[0], color='r', linestyle='--', alpha=0.5)\n    ax4.set_xlabel('Time (s)', fontsize=11)\n    ax4.set_ylabel('Acceleration (m/s²)', fontsize=11)\n    ax4.set_title('Control Inputs', fontsize=12, fontweight='bold')\n    ax4.legend()\n    ax4.grid(True, alpha=0.3)\n    \n    # 5. Velocity profile\n    ax5 = axes[1, 1]\n    speed = np.linalg.norm(states[:, 2:4], axis=1)\n    ax5.plot(time_vec, speed[:num_steps], 'b-', linewidth=2)\n    ax5.set_xlabel('Time (s)', fontsize=11)\n    ax5.set_ylabel('Speed (m/s)', fontsize=11)\n    ax5.set_title('Velocity Profile', fontsize=12, fontweight='bold')\n    ax5.grid(True, alpha=0.3)\n    \n    # 6. Metrics\n    ax6 = axes[1, 2]\n    ax6.axis('off')\n    \n    collision_check = all(d > mpc.obstacle_radius for d in min_distances)\n    safety_check = all(d > mpc.obstacle_radius + mpc.safety_margin for d in min_distances)\n    \n    final_error = np.linalg.norm(states[-1, :2] - goal[:2])\n    mean_control = np.mean(np.linalg.norm(controls, axis=1))\n    max_lateral_dev = np.max(np.abs(states[:, 1]))\n    \n    metrics_text = f\"\"\"\n    MPC OBSTACLE AVOIDANCE METRICS\n    {'='*45}\n    \n    Scenario:\n      Start:  ({start[0]:.1f}, {start[1]:.1f}) m\n      Goal:   ({goal[0]:.1f}, {goal[1]:.1f}) m\n      Duration: {time_vec[-1]:.1f} s\n    \n    Safety:\n      Min distance to obs:    {min(min_distances):.2f} m\n      Collision-free:         {'✓ YES' if collision_check else '✗ NO'}\n      Safety margin kept:     {'✓ YES' if safety_check else '✗ NO'}\n    \n    Performance:\n      Final position error:   {final_error:.2f} m\n      Max lateral deviation:  {max_lateral_dev:.2f} m\n      Mean control effort:    {mean_control:.2f} m/s²\n      Final speed:            {speed[-1]:.2f} m/s\n    \n    MPC Parameters:\n      Horizon (N):            {mpc.N} steps\n      Time step (dt):         {mpc.dt} s\n      Prediction time:        {mpc.N * mpc.dt:.1f} s\n      Obstacle weight:        {mpc.obstacle_weight:.0f}\n    \n    Result: {'SUCCESS ✓' if collision_check and final_error < 5.0 else 'PARTIAL'}\n    \"\"\"\n    \n    ax6.text(0.05, 0.95, metrics_text, transform=ax6.transAxes,\n             fontsize=9.5, verticalalignment='top', family='monospace',\n             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"=\"*70)\n    print(\"MPC OBSTACLE AVOIDANCE RESULTS\")\n    print(\"=\"*70)\n    print(f\"Collision-free:         {'YES' if collision_check else 'NO'}\")\n    print(f\"Safety margin kept:     {'YES' if safety_check else 'NO'}\")\n    print(f\"Min obstacle distance:  {min(min_distances):.2f} m\")\n    print(f\"Final position error:   {final_error:.2f} m\")\n    print(f\"Max lateral deviation:  {max_lateral_dev:.2f} m\")\n    print(\"=\"*70)\n\ndemonstrate_mpc_obstacle_avoidance()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 3. Model Predictive Control (MPC)\n\nModel Predictive Control is a **receding horizon** optimization technique that solves an optimal control problem at each time step.\n\n### MPC Algorithm\n\n**At each time step $k$:**\n\n1. **Measure** current state $x(k)$\n2. **Solve** finite-horizon optimal control problem:\n   $$\\min_{u_k, \\ldots, u_{k+N-1}} \\sum_{i=k}^{k+N-1} \\left[ \\|x_i - x_{ref,i}\\|_Q^2 + \\|u_i\\|_R^2 \\right] + \\|x_{k+N} - x_{ref,k+N}\\|_P^2$$\n   subject to dynamics and constraints\n3. **Apply** only the first control $u_k^*$\n4. **Repeat** at next time step (receding horizon)\n\n### Key Advantages\n\n- **Handles constraints** explicitly (actuator limits, obstacle avoidance)\n- **Preview capability** using future reference trajectory\n- **Online optimization** adapts to disturbances\n- **Multivariable** naturally handles coupled dynamics\n\n### MPC vs. Classical Control\n\n| Aspect | PID | LQR | MPC |\n|--------|-----|-----|-----|\n| Constraints | ✗ | ✗ | ✓ |\n| Preview | ✗ | ✗ | ✓ |\n| Optimality | ✗ | ✓ | ✓ |\n| Computation | Low | Medium | High |\n| Nonlinear | ✗ | ✗ | ✓ (NMPC) |\n\n### Applications in Autonomous Vehicles\n\n- **Adaptive Cruise Control (ACC)**: Maintain safe distance while tracking speed\n- **Lane Keeping Assist**: Track lane center with steering constraints\n- **Obstacle Avoidance**: Real-time replanning around dynamic obstacles\n- **Parking**: Optimize maneuvers with tight space constraints",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Exercises\n\n### Exercise 1: Multi-Objective Cost Function Tuning\n\n**Objective:** Implement and tune a trajectory optimizer with multiple competing objectives.\n\n**Task:** Create a trajectory optimization problem that balances:\n1. Minimizing travel time\n2. Maximizing comfort (minimizing acceleration)\n3. Maintaining safe distance from obstacles\n\n**Instructions:**\n- Define cost weights for each objective\n- Implement obstacle avoidance cost using distance penalties\n- Visualize the Pareto front showing trade-offs between objectives\n- Compare trajectories with different weight combinations\n\n### Exercise 2: MPC with Vehicle Dynamics\n\n**Objective:** Extend the MPC implementation to use realistic vehicle dynamics instead of point mass.\n\n**Task:** Implement MPC with the bicycle kinematic model:\n\n$$\n\\begin{align}\n\\dot{x} &= v \\cos(\\theta) \\\\\n\\dot{y} &= v \\sin(\\theta) \\\\\n\\dot{\\theta} &= \\frac{v}{L} \\tan(\\delta) \\\\\n\\dot{v} &= a\n\\end{align}\n$$\n\nWhere:\n- $(x, y)$ = position\n- $\\theta$ = heading angle\n- $v$ = velocity\n- $\\delta$ = steering angle (control input)\n- $a$ = acceleration (control input)\n- $L$ = wheelbase length\n\n**Instructions:**\n- Modify the `SimpleMPC` class to use bicycle model dynamics\n- Add constraints on steering angle: $|\\delta| \\leq \\delta_{max}$\n- Add constraints on steering rate: $|\\dot{\\delta}| \\leq \\dot{\\delta}_{max}$\n- Test on a lane change maneuver\n\n### Exercise 3: Receding Horizon Obstacle Avoidance\n\n**Objective:** Implement MPC-based real-time obstacle avoidance in a dynamic environment.\n\n**Task:** Create an MPC controller that:\n1. Tracks a reference path\n2. Avoids moving obstacles within the prediction horizon\n3. Re-plans at each time step as obstacles move\n\n**Instructions:**\n- Add obstacle positions as time-varying constraints\n- Implement collision checking within the optimization cost\n- Use soft constraints (penalty method) for obstacle avoidance\n- Visualize the predicted trajectory and actual path in real-time\n- Compare performance with different prediction horizons (N = 5, 10, 20)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Exercise Solutions\n\n# Exercise 1: Multi-Objective Cost Function Tuning\n# TODO: Implement multi-objective trajectory optimization\n# \n# Suggested approach:\n# 1. Define separate cost functions for each objective\n# 2. Create weighted sum: J_total = w1*J_time + w2*J_comfort + w3*J_safety\n# 3. Vary weights and collect optimal solutions\n# 4. Plot Pareto front showing trade-offs\n#\n# Example structure:\n# def multi_objective_cost(traj, weights, obstacles):\n#     J_time = trajectory_duration(traj)\n#     J_comfort = integrate_squared_acceleration(traj)\n#     J_safety = sum([penalty(distance(traj, obs)) for obs in obstacles])\n#     return weights[0]*J_time + weights[1]*J_comfort + weights[2]*J_safety\n\n\n# Exercise 2: MPC with Vehicle Dynamics\n# TODO: Implement bicycle model in MPC\n#\n# Suggested approach:\n# 1. Create BicycleMPC class extending SimpleMPC\n# 2. Redefine dynamics() method with bicycle kinematic model\n# 3. Update state vector to [x, y, theta, v]\n# 4. Update control vector to [delta, a]\n# 5. Add steering constraints in bounds\n#\n# Example structure:\n# class BicycleMPC(SimpleMPC):\n#     def __init__(self, wheelbase=2.7, **kwargs):\n#         super().__init__(**kwargs)\n#         self.L = wheelbase\n#         self.delta_max = np.deg2rad(30)  # Max steering angle\n#         \n#     def dynamics(self, state, control):\n#         x, y, theta, v = state\n#         delta, a = control\n#         \n#         # Bicycle model (use small-angle approximation or exact)\n#         x_next = x + v * np.cos(theta) * self.dt\n#         y_next = y + v * np.sin(theta) * self.dt\n#         theta_next = theta + (v / self.L) * np.tan(delta) * self.dt\n#         v_next = v + a * self.dt\n#         \n#         return np.array([x_next, y_next, theta_next, v_next])\n\n\n# Exercise 3: Receding Horizon Obstacle Avoidance\n# TODO: Implement MPC with dynamic obstacle avoidance\n#\n# Suggested approach:\n# 1. Extend SimpleMPC to include obstacle cost in cost function\n# 2. Predict obstacle positions over horizon\n# 3. Add soft constraint penalty for collision\n# 4. Re-solve at each time step\n#\n# Example structure:\n# class ObstacleAvoidanceMPC(SimpleMPC):\n#     def __init__(self, obstacle_radius=1.0, safety_margin=0.5, **kwargs):\n#         super().__init__(**kwargs)\n#         self.r_obs = obstacle_radius\n#         self.r_safe = safety_margin\n#     \n#     def obstacle_cost(self, state, obstacles_t):\n#         \"\"\"Compute collision penalty for given state and obstacle positions\"\"\"\n#         x, y = state[0], state[1]\n#         penalty = 0.0\n#         \n#         for obs in obstacles_t:\n#             dist = np.sqrt((x - obs[0])**2 + (y - obs[1])**2)\n#             min_dist = self.r_obs + self.r_safe\n#             \n#             if dist < min_dist:\n#                 # Quadratic penalty inside safety zone\n#                 penalty += 1000 * (min_dist - dist)**2\n#         \n#         return penalty\n#     \n#     def cost(self, z, x0, x_ref, obstacles_trajectory):\n#         \"\"\"Modified cost including obstacle avoidance\"\"\"\n#         controls = z.reshape((self.N, 2))\n#         states = [x0]\n#         total_cost = 0.0\n#         \n#         for k in range(self.N):\n#             # Tracking cost\n#             x_error = states[k] - x_ref[k]\n#             total_cost += x_error @ self.Q @ x_error\n#             \n#             # Control cost\n#             u = controls[k]\n#             total_cost += u @ self.R @ u\n#             \n#             # Obstacle avoidance cost\n#             total_cost += self.obstacle_cost(states[k], obstacles_trajectory[k])\n#             \n#             # Dynamics\n#             x_next = self.dynamics(states[k], u)\n#             states.append(x_next)\n#         \n#         # Terminal cost\n#         x_error_final = states[-1] - x_ref[-1]\n#         total_cost += x_error_final @ (self.Q * 10) @ x_error_final\n#         \n#         return total_cost\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## References\n\n### Books\n\n1. **Betts, J. T.** (2010). *Practical Methods for Optimal Control and Estimation Using Nonlinear Programming* (2nd ed.). SIAM.\n   - Comprehensive treatment of trajectory optimization methods\n   - Chapter 4: Direct transcription methods\n   - Chapter 7: Real-time optimization\n\n2. **Boyd, S., & Vandenberghe, L.** (2004). *Convex Optimization*. Cambridge University Press.\n   - Foundation for optimization theory\n   - Available free online: https://web.stanford.edu/~boyd/cvxbook/\n\n3. **Rawlings, J. B., Mayne, D. Q., & Diehl, M.** (2017). *Model Predictive Control: Theory, Computation, and Design* (2nd ed.). Nob Hill Publishing.\n   - Definitive reference for MPC\n   - Chapter 1: Introduction to MPC concepts\n   - Chapter 2: MPC stability and constraint handling\n\n4. **Lavalle, S. M.** (2006). *Planning Algorithms*. Cambridge University Press.\n   - Chapter 14: Optimal motion planning\n   - Free online: http://planning.cs.uiuc.edu/\n\n### Papers\n\n5. **Coulter, R. C.** (1992). *Implementation of the Pure Pursuit Path Tracking Algorithm*. CMU-RI-TR-92-01.\n   - Classic paper on trajectory tracking\n   - Foundation for many autonomous vehicle controllers\n\n6. **Werling, M., et al.** (2010). \"Optimal trajectory generation for dynamic street scenarios in a Frenet Frame.\" *IEEE International Conference on Robotics and Automation (ICRA)*.\n   - Frenet frame approach to trajectory optimization\n   - Widely used in industry for highway driving\n\n7. **Ziegler, J., & Stiller, C.** (2009). \"Spatiotemporal state lattices for fast trajectory planning in dynamic on-road driving scenarios.\" *IEEE/RSJ International Conference on Intelligent Robots and Systems*.\n   - State lattice planning with temporal dimension\n   - Used in DARPA Urban Challenge winner\n\n8. **Paden, B., et al.** (2016). \"A Survey of Motion Planning and Control Techniques for Self-Driving Urban Vehicles.\" *IEEE Transactions on Intelligent Vehicles*, 1(1), 33-55.\n   - Excellent overview of planning and control methods\n   - Section IV covers trajectory optimization\n\n9. **Verschueren, R., et al.** (2019). \"Towards a modular software package for embedded optimization.\" *IFAC-PapersOnLine*, 52(1), 164-169.\n   - Modern computational methods for real-time MPC\n   - Code generation for embedded systems\n\n### Online Resources\n\n10. **MathWorks - Understanding Model Predictive Control**\n    - https://www.mathworks.com/videos/series/understanding-model-predictive-control.html\n    - Video series explaining MPC fundamentals\n\n11. **CasADi - Optimization Framework**\n    - https://web.casadi.org/\n    - Powerful symbolic framework for numerical optimization\n    - Widely used for trajectory optimization in research\n\n12. **ACADO Toolkit**\n    - http://acado.github.io/\n    - Open-source toolkit for automatic control and dynamic optimization\n    - Implements multiple direct methods\n\n13. **CVXPy - Convex Optimization**\n    - https://www.cvxpy.org/\n    - Python library for convex optimization\n    - Example: https://www.cvxpy.org/examples/applications/optimal_control.html\n\n### Software & Tools\n\n14. **Drake** - Model-based design and verification for robotics\n    - https://drake.mit.edu/\n    - Trajectory optimization examples: https://deepnote.com/workspace/Drake-0b3b2c53-a7ad-441b-80f8-bf8350752305/project/Tutorials-2b4fc509-aef2-417d-a40d-6071dfed9199/%2Ftrajectory_optimization.ipynb\n\n15. **OMPL** - Open Motion Planning Library\n    - https://ompl.kavrakilab.org/\n    - Includes optimization-based planners\n\n16. **PyDy** - Python Dynamics\n    - https://www.pydy.org/\n    - Symbolic dynamics for complex mechanical systems\n\n### Research Groups & Courses\n\n17. **Stanford AA203: Optimal and Learning-Based Control**\n    - Course materials: https://stanfordasl.github.io/aa203/\n    - Lecture notes on trajectory optimization and MPC\n\n18. **MIT 6.832: Underactuated Robotics**\n    - http://underactuated.mit.edu/\n    - Chapter 10: Trajectory optimization\n    - Interactive notebooks with examples\n\n19. **Berkeley MPC Lab**\n    - https://borrelli.me.berkeley.edu/\n    - Research on MPC for autonomous vehicles\n    - Publications and code repositories\n\n### Related Topics\n\n20. **Kelly, M.** (2017). \"An Introduction to Trajectory Optimization: How to Do Your Own Direct Collocation.\" *SIAM Review*, 59(4), 849-904.\n    - Tutorial paper with MATLAB code\n    - Excellent practical introduction to direct methods\n\n21. **Schulman, J., et al.** (2013). \"Finding Locally Optimal, Collision-Free Trajectories with Sequential Convex Optimization.\" *Robotics: Science and Systems*.\n    - TrajOpt algorithm for robot motion planning\n    - Handles non-convex constraints efficiently"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}