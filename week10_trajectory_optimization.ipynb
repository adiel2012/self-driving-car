{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10: Trajectory Optimization\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "- Cost Functions (smoothness, speed, safety); Model Predictive Control (MPC) for planning and control integration; Real-time constraints\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Understand the key concepts\n",
    "2. Implement algorithms\n",
    "3. Apply techniques to real-world problems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle, Circle, Polygon, FancyArrowPatch\nfrom matplotlib.animation import FuncAnimation\nfrom scipy.optimize import minimize\nfrom scipy.interpolate import CubicSpline\n\n# Set random seed for reproducibility\nnp.random.seed(42)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Trajectory Optimization Fundamentals\n\nTrajectory optimization finds the **best** trajectory that satisfies constraints while minimizing a cost function.\n\n### Trajectory vs. Path\n\n- **Path**: Geometric curve in space (no time information)\n  - Example: $(x(s), y(s))$ where $s \\in [0, 1]$\n  \n- **Trajectory**: Path with timing information\n  - Example: $(x(t), y(t), v(t))$ where $t$ is time\n\n### Optimization Problem Formulation\n\n**Decision Variables:** Trajectory parameters $\\mathbf{z} = [x_0, x_1, \\ldots, x_N, u_0, u_1, \\ldots, u_{N-1}]$\n\n**Minimize:**\n$$J(\\mathbf{z}) = \\phi(x_N) + \\sum_{k=0}^{N-1} L(x_k, u_k)$$\n\n**Subject to:**\n- **Dynamics:** $x_{k+1} = f(x_k, u_k)$\n- **Initial conditions:** $x_0 = x_{init}$\n- **Goal constraints:** $x_N \\in \\mathcal{X}_{goal}$\n- **State constraints:** $x_k \\in \\mathcal{X}_{safe}$\n- **Control constraints:** $u_k \\in \\mathcal{U}$\n\nWhere:\n- $x_k$: State at time step $k$ (position, velocity, heading)\n- $u_k$: Control input (steering, acceleration)\n- $\\phi(x_N)$: Terminal cost\n- $L(x_k, u_k)$: Stage cost\n\n### Cost Function Components\n\n**1. Smoothness:**\n$$J_{smooth} = \\int_0^T \\left( \\left(\\frac{d^2x}{dt^2}\\right)^2 + \\left(\\frac{d^2y}{dt^2}\\right)^2 \\right) dt$$\nPenalizes high accelerations (jerk minimization)\n\n**2. Speed:**\n$$J_{speed} = \\int_0^T (v_{ref} - v(t))^2 dt$$\nTracks desired speed\n\n**3. Safety (Obstacle Avoidance):**\n$$J_{safety} = \\sum_{obstacles} \\max(0, d_{safe} - d(x, obs))^2$$\nPenalizes being too close to obstacles\n\n**4. Control Effort:**\n$$J_{control} = \\int_0^T (u(t)^T R u(t)) dt$$\nMinimizes steering and acceleration inputs\n\n**Total Cost:**\n$$J = w_1 J_{smooth} + w_2 J_{speed} + w_3 J_{safety} + w_4 J_{control}$$"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simple MPC Implementation for Vehicle Tracking\n\nclass SimpleMPC:\n    \"\"\"Model Predictive Controller for 2D point mass\"\"\"\n    \n    def __init__(self, horizon=10, dt=0.1, Q=None, R=None):\n        \"\"\"\n        Initialize MPC\n        \n        Parameters:\n        - horizon: Prediction horizon steps\n        - dt: Time step\n        - Q: State cost matrix (4x4)\n        - R: Control cost matrix (2x2)\n        \"\"\"\n        self.N = horizon\n        self.dt = dt\n        \n        # Cost matrices\n        self.Q = Q if Q is not None else np.diag([10.0, 10.0, 1.0, 1.0])  # [x, y, vx, vy]\n        self.R = R if R is not None else np.diag([0.1, 0.1])  # [ax, ay]\n        \n        # Control limits\n        self.u_max = np.array([3.0, 3.0])  # Max acceleration (m/s²)\n        self.u_min = -self.u_max\n    \n    def dynamics(self, state, control):\n        \"\"\"\n        Simple 2D point mass dynamics\n        state: [x, y, vx, vy]\n        control: [ax, ay]\n        \"\"\"\n        x, y, vx, vy = state\n        ax, ay = control\n        \n        # Integrate with Euler method\n        x_next = x + vx * self.dt\n        y_next = y + vy * self.dt\n        vx_next = vx + ax * self.dt\n        vy_next = vy + ay * self.dt\n        \n        return np.array([x_next, y_next, vx_next, vy_next])\n    \n    def cost(self, z, x0, x_ref):\n        \"\"\"\n        Compute total cost for decision variables z\n        \n        z: Flattened array of [u_0, ..., u_{N-1}]\n        x0: Initial state\n        x_ref: Reference trajectory (N+1 x 4)\n        \"\"\"\n        # Reshape controls\n        controls = z.reshape((self.N, 2))\n        \n        # Simulate forward\n        states = [x0]\n        total_cost = 0.0\n        \n        for k in range(self.N):\n            # State cost\n            x_error = states[k] - x_ref[k]\n            total_cost += x_error @ self.Q @ x_error\n            \n            # Control cost\n            u = controls[k]\n            total_cost += u @ self.R @ u\n            \n            # Propagate dynamics\n            x_next = self.dynamics(states[k], u)\n            states.append(x_next)\n        \n        # Terminal cost\n        x_error_final = states[-1] - x_ref[-1]\n        total_cost += x_error_final @ (self.Q * 10) @ x_error_final\n        \n        return total_cost\n    \n    def solve(self, x0, x_ref):\n        \"\"\"\n        Solve MPC optimization\n        \n        x0: Current state\n        x_ref: Reference trajectory (N+1 x 4)\n        \n        Returns: Optimal control sequence\n        \"\"\"\n        # Initial guess (zero acceleration)\n        u_init = np.zeros(self.N * 2)\n        \n        # Bounds on controls\n        bounds = [(self.u_min[i % 2], self.u_max[i % 2]) for i in range(self.N * 2)]\n        \n        # Solve optimization\n        result = minimize(\n            fun=lambda z: self.cost(z, x0, x_ref),\n            x0=u_init,\n            method='SLSQP',\n            bounds=bounds,\n            options={'maxiter': 100, 'disp': False}\n        )\n        \n        # Reshape to controls\n        u_opt = result.x.reshape((self.N, 2))\n        return u_opt\n\n\n# Simulate MPC tracking a reference trajectory\ndef simulate_mpc_tracking():\n    # Reference trajectory (figure-8)\n    t_ref = np.linspace(0, 10, 100)\n    x_ref = 20 * np.sin(t_ref)\n    y_ref = 10 * np.sin(2 * t_ref)\n    \n    # Reference velocities (numerical derivative)\n    vx_ref = np.gradient(x_ref, t_ref)\n    vy_ref = np.gradient(y_ref, t_ref)\n    \n    reference_traj = np.column_stack([x_ref, y_ref, vx_ref, vy_ref])\n    \n    # Initialize MPC\n    mpc = SimpleMPC(horizon=10, dt=0.1)\n    \n    # Initial state\n    x_current = np.array([0.0, 0.0, 0.0, 0.0])\n    \n    # Simulate\n    states = [x_current]\n    controls = []\n    \n    num_steps = len(reference_traj) - mpc.N - 1\n    \n    print(\"Running MPC simulation...\")\n    for i in range(num_steps):\n        # Get reference for horizon\n        x_ref_horizon = reference_traj[i:i+mpc.N+1]\n        \n        # Solve MPC\n        u_opt = mpc.solve(x_current, x_ref_horizon)\n        \n        # Apply first control\n        u_apply = u_opt[0]\n        controls.append(u_apply)\n        \n        # Simulate system\n        x_current = mpc.dynamics(x_current, u_apply)\n        states.append(x_current)\n        \n        if i % 10 == 0:\n            print(f\"  Step {i}/{num_steps}\")\n    \n    states = np.array(states)\n    controls = np.array(controls)\n    \n    # Visualization\n    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n    \n    # Trajectory tracking\n    ax1 = axes[0, 0]\n    ax1.plot(reference_traj[:, 0], reference_traj[:, 1], 'g--', linewidth=2, label='Reference', alpha=0.7)\n    ax1.plot(states[:, 0], states[:, 1], 'b-', linewidth=2, label='MPC Tracking')\n    ax1.plot(states[0, 0], states[0, 1], 'go', markersize=10, label='Start')\n    ax1.set_xlabel('X Position (m)')\n    ax1.set_ylabel('Y Position (m)')\n    ax1.set_title('MPC Trajectory Tracking')\n    ax1.legend()\n    ax1.grid(True)\n    ax1.axis('equal')\n    \n    # Tracking error\n    ax2 = axes[0, 1]\n    tracking_error = np.linalg.norm(states[:num_steps, :2] - reference_traj[:num_steps, :2], axis=1)\n    time_vec = np.arange(num_steps) * mpc.dt\n    ax2.plot(time_vec, tracking_error, 'r-', linewidth=2)\n    ax2.set_xlabel('Time (s)')\n    ax2.set_ylabel('Position Error (m)')\n    ax2.set_title(f'Tracking Error (Mean: {np.mean(tracking_error):.2f}m)')\n    ax2.grid(True)\n    \n    # Control inputs\n    ax3 = axes[1, 0]\n    ax3.plot(time_vec, controls[:, 0], label='ax (longitudinal)')\n    ax3.plot(time_vec, controls[:, 1], label='ay (lateral)')\n    ax3.axhline(mpc.u_max[0], color='r', linestyle='--', alpha=0.5, label='Limits')\n    ax3.axhline(mpc.u_min[0], color='r', linestyle='--', alpha=0.5)\n    ax3.set_xlabel('Time (s)')\n    ax3.set_ylabel('Acceleration (m/s²)')\n    ax3.set_title('Control Inputs')\n    ax3.legend()\n    ax3.grid(True)\n    \n    # Velocity profile\n    ax4 = axes[1, 1]\n    speed = np.linalg.norm(states[:, 2:4], axis=1)\n    ref_speed = np.linalg.norm(reference_traj[:len(speed), 2:4], axis=1)\n    ax4.plot(time_vec, speed[:num_steps], 'b-', label='Actual Speed', linewidth=2)\n    ax4.plot(time_vec, ref_speed[:num_steps], 'g--', label='Reference Speed', linewidth=2, alpha=0.7)\n    ax4.set_xlabel('Time (s)')\n    ax4.set_ylabel('Speed (m/s)')\n    ax4.set_title('Velocity Tracking')\n    ax4.legend()\n    ax4.grid(True)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"\\nMPC Performance:\")\n    print(f\"  Mean tracking error: {np.mean(tracking_error):.3f} m\")\n    print(f\"  Max tracking error: {np.max(tracking_error):.3f} m\")\n    print(f\"  Mean control magnitude: {np.mean(np.linalg.norm(controls, axis=1)):.3f} m/s²\")\n\nsimulate_mpc_tracking()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Exercises\n\n### Exercise 1: Multi-Objective Cost Function Tuning\n\n**Objective:** Implement and tune a trajectory optimizer with multiple competing objectives.\n\n**Task:** Create a trajectory optimization problem that balances:\n1. Minimizing travel time\n2. Maximizing comfort (minimizing acceleration)\n3. Maintaining safe distance from obstacles\n\n**Instructions:**\n- Define cost weights for each objective\n- Implement obstacle avoidance cost using distance penalties\n- Visualize the Pareto front showing trade-offs between objectives\n- Compare trajectories with different weight combinations\n\n### Exercise 2: MPC with Vehicle Dynamics\n\n**Objective:** Extend the MPC implementation to use realistic vehicle dynamics instead of point mass.\n\n**Task:** Implement MPC with the bicycle kinematic model:\n\n$$\n\\begin{align}\n\\dot{x} &= v \\cos(\\theta) \\\\\n\\dot{y} &= v \\sin(\\theta) \\\\\n\\dot{\\theta} &= \\frac{v}{L} \\tan(\\delta) \\\\\n\\dot{v} &= a\n\\end{align}\n$$\n\nWhere:\n- $(x, y)$ = position\n- $\\theta$ = heading angle\n- $v$ = velocity\n- $\\delta$ = steering angle (control input)\n- $a$ = acceleration (control input)\n- $L$ = wheelbase length\n\n**Instructions:**\n- Modify the `SimpleMPC` class to use bicycle model dynamics\n- Add constraints on steering angle: $|\\delta| \\leq \\delta_{max}$\n- Add constraints on steering rate: $|\\dot{\\delta}| \\leq \\dot{\\delta}_{max}$\n- Test on a lane change maneuver\n\n### Exercise 3: Receding Horizon Obstacle Avoidance\n\n**Objective:** Implement MPC-based real-time obstacle avoidance in a dynamic environment.\n\n**Task:** Create an MPC controller that:\n1. Tracks a reference path\n2. Avoids moving obstacles within the prediction horizon\n3. Re-plans at each time step as obstacles move\n\n**Instructions:**\n- Add obstacle positions as time-varying constraints\n- Implement collision checking within the optimization cost\n- Use soft constraints (penalty method) for obstacle avoidance\n- Visualize the predicted trajectory and actual path in real-time\n- Compare performance with different prediction horizons (N = 5, 10, 20)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Exercise Solutions\n\n# Exercise 1: Multi-Objective Cost Function Tuning\n# TODO: Implement multi-objective trajectory optimization\n# \n# Suggested approach:\n# 1. Define separate cost functions for each objective\n# 2. Create weighted sum: J_total = w1*J_time + w2*J_comfort + w3*J_safety\n# 3. Vary weights and collect optimal solutions\n# 4. Plot Pareto front showing trade-offs\n#\n# Example structure:\n# def multi_objective_cost(traj, weights, obstacles):\n#     J_time = trajectory_duration(traj)\n#     J_comfort = integrate_squared_acceleration(traj)\n#     J_safety = sum([penalty(distance(traj, obs)) for obs in obstacles])\n#     return weights[0]*J_time + weights[1]*J_comfort + weights[2]*J_safety\n\n\n# Exercise 2: MPC with Vehicle Dynamics\n# TODO: Implement bicycle model in MPC\n#\n# Suggested approach:\n# 1. Create BicycleMPC class extending SimpleMPC\n# 2. Redefine dynamics() method with bicycle kinematic model\n# 3. Update state vector to [x, y, theta, v]\n# 4. Update control vector to [delta, a]\n# 5. Add steering constraints in bounds\n#\n# Example structure:\n# class BicycleMPC(SimpleMPC):\n#     def __init__(self, wheelbase=2.7, **kwargs):\n#         super().__init__(**kwargs)\n#         self.L = wheelbase\n#         self.delta_max = np.deg2rad(30)  # Max steering angle\n#         \n#     def dynamics(self, state, control):\n#         x, y, theta, v = state\n#         delta, a = control\n#         \n#         # Bicycle model (use small-angle approximation or exact)\n#         x_next = x + v * np.cos(theta) * self.dt\n#         y_next = y + v * np.sin(theta) * self.dt\n#         theta_next = theta + (v / self.L) * np.tan(delta) * self.dt\n#         v_next = v + a * self.dt\n#         \n#         return np.array([x_next, y_next, theta_next, v_next])\n\n\n# Exercise 3: Receding Horizon Obstacle Avoidance\n# TODO: Implement MPC with dynamic obstacle avoidance\n#\n# Suggested approach:\n# 1. Extend SimpleMPC to include obstacle cost in cost function\n# 2. Predict obstacle positions over horizon\n# 3. Add soft constraint penalty for collision\n# 4. Re-solve at each time step\n#\n# Example structure:\n# class ObstacleAvoidanceMPC(SimpleMPC):\n#     def __init__(self, obstacle_radius=1.0, safety_margin=0.5, **kwargs):\n#         super().__init__(**kwargs)\n#         self.r_obs = obstacle_radius\n#         self.r_safe = safety_margin\n#     \n#     def obstacle_cost(self, state, obstacles_t):\n#         \"\"\"Compute collision penalty for given state and obstacle positions\"\"\"\n#         x, y = state[0], state[1]\n#         penalty = 0.0\n#         \n#         for obs in obstacles_t:\n#             dist = np.sqrt((x - obs[0])**2 + (y - obs[1])**2)\n#             min_dist = self.r_obs + self.r_safe\n#             \n#             if dist < min_dist:\n#                 # Quadratic penalty inside safety zone\n#                 penalty += 1000 * (min_dist - dist)**2\n#         \n#         return penalty\n#     \n#     def cost(self, z, x0, x_ref, obstacles_trajectory):\n#         \"\"\"Modified cost including obstacle avoidance\"\"\"\n#         controls = z.reshape((self.N, 2))\n#         states = [x0]\n#         total_cost = 0.0\n#         \n#         for k in range(self.N):\n#             # Tracking cost\n#             x_error = states[k] - x_ref[k]\n#             total_cost += x_error @ self.Q @ x_error\n#             \n#             # Control cost\n#             u = controls[k]\n#             total_cost += u @ self.R @ u\n#             \n#             # Obstacle avoidance cost\n#             total_cost += self.obstacle_cost(states[k], obstacles_trajectory[k])\n#             \n#             # Dynamics\n#             x_next = self.dynamics(states[k], u)\n#             states.append(x_next)\n#         \n#         # Terminal cost\n#         x_error_final = states[-1] - x_ref[-1]\n#         total_cost += x_error_final @ (self.Q * 10) @ x_error_final\n#         \n#         return total_cost\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## References\n\n### Books\n\n1. **Betts, J. T.** (2010). *Practical Methods for Optimal Control and Estimation Using Nonlinear Programming* (2nd ed.). SIAM.\n   - Comprehensive treatment of trajectory optimization methods\n   - Chapter 4: Direct transcription methods\n   - Chapter 7: Real-time optimization\n\n2. **Boyd, S., & Vandenberghe, L.** (2004). *Convex Optimization*. Cambridge University Press.\n   - Foundation for optimization theory\n   - Available free online: https://web.stanford.edu/~boyd/cvxbook/\n\n3. **Rawlings, J. B., Mayne, D. Q., & Diehl, M.** (2017). *Model Predictive Control: Theory, Computation, and Design* (2nd ed.). Nob Hill Publishing.\n   - Definitive reference for MPC\n   - Chapter 1: Introduction to MPC concepts\n   - Chapter 2: MPC stability and constraint handling\n\n4. **Lavalle, S. M.** (2006). *Planning Algorithms*. Cambridge University Press.\n   - Chapter 14: Optimal motion planning\n   - Free online: http://planning.cs.uiuc.edu/\n\n### Papers\n\n5. **Coulter, R. C.** (1992). *Implementation of the Pure Pursuit Path Tracking Algorithm*. CMU-RI-TR-92-01.\n   - Classic paper on trajectory tracking\n   - Foundation for many autonomous vehicle controllers\n\n6. **Werling, M., et al.** (2010). \"Optimal trajectory generation for dynamic street scenarios in a Frenet Frame.\" *IEEE International Conference on Robotics and Automation (ICRA)*.\n   - Frenet frame approach to trajectory optimization\n   - Widely used in industry for highway driving\n\n7. **Ziegler, J., & Stiller, C.** (2009). \"Spatiotemporal state lattices for fast trajectory planning in dynamic on-road driving scenarios.\" *IEEE/RSJ International Conference on Intelligent Robots and Systems*.\n   - State lattice planning with temporal dimension\n   - Used in DARPA Urban Challenge winner\n\n8. **Paden, B., et al.** (2016). \"A Survey of Motion Planning and Control Techniques for Self-Driving Urban Vehicles.\" *IEEE Transactions on Intelligent Vehicles*, 1(1), 33-55.\n   - Excellent overview of planning and control methods\n   - Section IV covers trajectory optimization\n\n9. **Verschueren, R., et al.** (2019). \"Towards a modular software package for embedded optimization.\" *IFAC-PapersOnLine*, 52(1), 164-169.\n   - Modern computational methods for real-time MPC\n   - Code generation for embedded systems\n\n### Online Resources\n\n10. **MathWorks - Understanding Model Predictive Control**\n    - https://www.mathworks.com/videos/series/understanding-model-predictive-control.html\n    - Video series explaining MPC fundamentals\n\n11. **CasADi - Optimization Framework**\n    - https://web.casadi.org/\n    - Powerful symbolic framework for numerical optimization\n    - Widely used for trajectory optimization in research\n\n12. **ACADO Toolkit**\n    - http://acado.github.io/\n    - Open-source toolkit for automatic control and dynamic optimization\n    - Implements multiple direct methods\n\n13. **CVXPy - Convex Optimization**\n    - https://www.cvxpy.org/\n    - Python library for convex optimization\n    - Example: https://www.cvxpy.org/examples/applications/optimal_control.html\n\n### Software & Tools\n\n14. **Drake** - Model-based design and verification for robotics\n    - https://drake.mit.edu/\n    - Trajectory optimization examples: https://deepnote.com/workspace/Drake-0b3b2c53-a7ad-441b-80f8-bf8350752305/project/Tutorials-2b4fc509-aef2-417d-a40d-6071dfed9199/%2Ftrajectory_optimization.ipynb\n\n15. **OMPL** - Open Motion Planning Library\n    - https://ompl.kavrakilab.org/\n    - Includes optimization-based planners\n\n16. **PyDy** - Python Dynamics\n    - https://www.pydy.org/\n    - Symbolic dynamics for complex mechanical systems\n\n### Research Groups & Courses\n\n17. **Stanford AA203: Optimal and Learning-Based Control**\n    - Course materials: https://stanfordasl.github.io/aa203/\n    - Lecture notes on trajectory optimization and MPC\n\n18. **MIT 6.832: Underactuated Robotics**\n    - http://underactuated.mit.edu/\n    - Chapter 10: Trajectory optimization\n    - Interactive notebooks with examples\n\n19. **Berkeley MPC Lab**\n    - https://borrelli.me.berkeley.edu/\n    - Research on MPC for autonomous vehicles\n    - Publications and code repositories\n\n### Related Topics\n\n20. **Kelly, M.** (2017). \"An Introduction to Trajectory Optimization: How to Do Your Own Direct Collocation.\" *SIAM Review*, 59(4), 849-904.\n    - Tutorial paper with MATLAB code\n    - Excellent practical introduction to direct methods\n\n21. **Schulman, J., et al.** (2013). \"Finding Locally Optimal, Collision-Free Trajectories with Sequential Convex Optimization.\" *Robotics: Science and Systems*.\n    - TrajOpt algorithm for robot motion planning\n    - Handles non-convex constraints efficiently"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}