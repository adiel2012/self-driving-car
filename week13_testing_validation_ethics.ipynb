{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 13: Testing, Validation, & Ethics\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "- Hardware-in-the-Loop (HIL) and Software-in-the-Loop (SIL) simulation; Edge Cases and Scenario Testing; AV Ethics (Liability, The Trolley Problem)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Understand the key concepts\n",
    "2. Implement algorithms\n",
    "3. Apply techniques to real-world problems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle, Circle, FancyBboxPatch, Polygon, Wedge\nfrom matplotlib.collections import PatchCollection\nfrom dataclasses import dataclass\nfrom typing import List, Tuple\nimport itertools\n\n# Set random seed for reproducibility\nnp.random.seed(42)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Testing and Validation Fundamentals\n\nTesting and validation are critical for ensuring autonomous vehicle safety and reliability.\n\n### Verification vs. Validation\n\n**Verification**: \"Are we building the product right?\"\n- Confirms implementation matches specification\n- Methods: Unit tests, integration tests, code review\n- Question: Does the code do what we designed?\n\n**Validation**: \"Are we building the right product?\"\n- Confirms system meets user needs and safety goals\n- Methods: Field testing, user studies, scenario testing\n- Question: Does the system solve the actual problem safely?\n\n### Testing Pyramid for Autonomous Vehicles\n\n```\n                 /\\\n                /  \\  Field Testing (Hours-Days)\n               /    \\\n              /------\\\n             / System \\ Integration Testing (Minutes-Hours)\n            /  Tests   \\\n           /------------\\\n          /  Component   \\ Unit Tests (Milliseconds-Seconds)\n         /     Tests      \\\n        /------------------\\\n       /   Simulation (XiL)  \\ Simulation Testing (Microseconds-Milliseconds)\n      /----------------------\\\n```\n\n**Bottom to Top:**\n1. **Simulation (XiL)**: Model/Software/Hardware-in-the-Loop\n2. **Unit Tests**: Individual functions and modules\n3. **Component Tests**: Subsystems (perception, planning, control)\n4. **Integration Tests**: Full stack on test track\n5. **Field Testing**: Real-world driving\n\n### Types of Testing\n\n**1. Functional Testing**\n- Does each feature work as specified?\n- Example: Lane keeping maintains center of lane ± 0.3m\n\n**2. Performance Testing**\n- How well does it work?\n- Example: Object detection achieves 95% recall at 100m\n\n**3. Safety Testing**\n- What happens when things go wrong?\n- Example: System safely stops when sensor fails\n\n**4. Robustness Testing**\n- How does it handle edge cases?\n- Example: Performance in fog, rain, direct sunlight\n\n**5. Regression Testing**\n- Did new changes break existing functionality?\n- Automated test suites run on every code change\n\n---\n\n## 2. Simulation-Based Testing\n\nSimulation enables faster, cheaper, and safer testing than real-world driving.\n\n### X-in-the-Loop (XiL) Testing\n\n**Model-in-the-Loop (MiL)**\n- Pure software simulation\n- Algorithms run on development PC\n- Fastest iteration, lowest fidelity\n- Use: Algorithm development\n\n**Software-in-the-Loop (SiL)**\n- Production code compiled for PC\n- Tests actual software implementation\n- Use: Software verification\n\n**Hardware-in-the-Loop (HIL)**\n- Real ECU hardware, simulated environment\n- Sensors receive synthetic signals\n- Highest fidelity before vehicle\n- Use: Integration testing\n\n**Vehicle-in-the-Loop (ViL)**\n- Real vehicle on dynamometer\n- Virtual environment projected\n- Use: Final validation\n\n### Simulation Fidelity Levels\n\n**Level 1: Kinematic**\n- Simple physics (no tire forces)\n- Fast, used for path planning\n\n**Level 2: Dynamic**\n- Tire models, suspension\n- Used for control testing\n\n**Level 3: High-Fidelity**\n- Detailed sensor models (ray-tracing for lidar)\n- Weather, lighting effects\n- Used for perception testing\n\n**Level 4: Photo-Realistic**\n- Game-engine graphics\n- Used for camera algorithm validation\n\n### Simulation Advantages & Limitations\n\n**Advantages:**\n- **Safety**: Test dangerous scenarios without risk\n- **Speed**: Run 10-100x faster than real-time\n- **Coverage**: Test rare events (e.g., tire blowout)\n- **Reproducibility**: Exact replay for debugging\n- **Cost**: No physical vehicle/track needed\n\n**Limitations:**\n- **Sim2Real Gap**: Simulated sensors ≠ real sensors\n- **Unknown Unknowns**: Can't simulate what you haven't modeled\n- **Validation**: How to validate the simulator itself?\n- **Complexity**: High-fidelity sims are expensive to build"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Implementation: Simple SIL Simulation Framework\n\n@dataclass\nclass VehicleState:\n    \"\"\"Vehicle state representation\"\"\"\n    x: float = 0.0\n    y: float = 0.0\n    heading: float = 0.0\n    velocity: float = 0.0\n\n@dataclass\nclass SensorReading:\n    \"\"\"Simulated sensor reading\"\"\"\n    distance: float\n    angle: float\n    object_type: str\n\nclass VehicleSimulator:\n    \"\"\"Software-in-the-Loop vehicle simulator\"\"\"\n    \n    def __init__(self, dt=0.1):\n        self.dt = dt\n        self.state = VehicleState()\n        self.obstacles = []\n    \n    def add_obstacle(self, x, y, radius=1.0, obj_type='vehicle'):\n        \"\"\"Add obstacle to environment\"\"\"\n        self.obstacles.append({'x': x, 'y': y, 'radius': radius, 'type': obj_type})\n    \n    def simulate_sensor(self, sensor_range=50.0, sensor_fov=np.pi):\n        \"\"\"Simulate range sensor (lidar/radar)\"\"\"\n        readings = []\n        \n        for obs in self.obstacles:\n            # Calculate relative position\n            dx = obs['x'] - self.state.x\n            dy = obs['y'] - self.state.y\n            distance = np.sqrt(dx**2 + dy**2)\n            angle = np.arctan2(dy, dx) - self.state.heading\n            \n            # Normalize angle to [-pi, pi]\n            angle = (angle + np.pi) % (2 * np.pi) - np.pi\n            \n            # Check if in sensor FOV and range\n            if distance <= sensor_range and abs(angle) <= sensor_fov / 2:\n                # Add measurement noise\n                noisy_distance = distance + np.random.normal(0, 0.1)\n                noisy_angle = angle + np.random.normal(0, 0.01)\n                \n                readings.append(SensorReading(\n                    distance=max(0, noisy_distance),\n                    angle=noisy_angle,\n                    object_type=obs['type']\n                ))\n        \n        return readings\n    \n    def apply_control(self, acceleration, steering_angle):\n        \"\"\"Apply control inputs and update state\"\"\"\n        # Simple kinematic bicycle model\n        L = 2.5  # Wheelbase\n        \n        # Update velocity\n        self.state.velocity += acceleration * self.dt\n        self.state.velocity = np.clip(self.state.velocity, 0, 30)  # 0-30 m/s\n        \n        # Update heading\n        self.state.heading += (self.state.velocity / L) * np.tan(steering_angle) * self.dt\n        \n        # Update position\n        self.state.x += self.state.velocity * np.cos(self.state.heading) * self.dt\n        self.state.y += self.state.velocity * np.sin(self.state.heading) * self.dt\n        \n        return self.state\n\n\nclass SimpleACC:\n    \"\"\"Adaptive Cruise Control algorithm under test\"\"\"\n    \n    def __init__(self, target_speed=20.0, safe_distance=10.0):\n        self.target_speed = target_speed\n        self.safe_distance = safe_distance\n        self.Kp = 0.5  # Proportional gain\n    \n    def compute_control(self, current_velocity, sensor_readings):\n        \"\"\"Compute acceleration command based on sensor readings\"\"\"\n        # Find closest obstacle ahead\n        closest_distance = float('inf')\n        \n        for reading in sensor_readings:\n            # Only consider objects roughly ahead (within ±30 degrees)\n            if abs(reading.angle) < np.deg2rad(30):\n                if reading.distance < closest_distance:\n                    closest_distance = reading.distance\n        \n        # If obstacle detected, maintain safe distance\n        if closest_distance < self.safe_distance * 2:\n            # Slow down\n            error = (closest_distance - self.safe_distance) * 0.3\n            acceleration = self.Kp * error\n        else:\n            # Speed up to target speed\n            error = self.target_speed - current_velocity\n            acceleration = self.Kp * error\n        \n        # Clip acceleration\n        return np.clip(acceleration, -3.0, 2.0)\n\n\n# Demonstration: SIL Testing of ACC\ndef demonstrate_sil_testing():\n    print(\"=== Software-in-the-Loop (SIL) Testing ===\\n\")\n    print(\"Testing Adaptive Cruise Control Algorithm\\n\")\n    \n    # Create simulator\n    sim = VehicleSimulator(dt=0.1)\n    \n    # Create ACC controller\n    acc = SimpleACC(target_speed=20.0, safe_distance=10.0)\n    \n    # Test scenario: Vehicle ahead decelerates\n    print(\"Scenario: Following vehicle that decelerates\\n\")\n    \n    # Add leading vehicle\n    lead_vehicle_x = 30.0\n    lead_vehicle_speed = 20.0\n    \n    # Simulation loop\n    time_steps = 200\n    history = {\n        'time': [],\n        'ego_x': [],\n        'ego_v': [],\n        'lead_x': [],\n        'distance': [],\n        'acceleration': []\n    }\n    \n    for t in range(time_steps):\n        time = t * sim.dt\n        \n        # Update lead vehicle position (decelerate after t=5s)\n        if time > 5.0:\n            lead_vehicle_speed = max(10.0, lead_vehicle_speed - 0.05)\n        lead_vehicle_x += lead_vehicle_speed * sim.dt\n        \n        # Clear and re-add obstacles\n        sim.obstacles = []\n        sim.add_obstacle(lead_vehicle_x, 0, radius=2.0, obj_type='vehicle')\n        \n        # Simulate sensors\n        readings = sim.simulate_sensor()\n        \n        # Compute control\n        accel_cmd = acc.compute_control(sim.state.velocity, readings)\n        \n        # Apply control (no steering for this test)\n        sim.apply_control(accel_cmd, 0.0)\n        \n        # Record history\n        distance = lead_vehicle_x - sim.state.x if len(readings) > 0 else float('inf')\n        history['time'].append(time)\n        history['ego_x'].append(sim.state.x)\n        history['ego_v'].append(sim.state.velocity)\n        history['lead_x'].append(lead_vehicle_x)\n        history['distance'].append(distance)\n        history['acceleration'].append(accel_cmd)\n    \n    # Analyze results\n    min_distance = min(history['distance'])\n    collision = min_distance < 2.0  # Vehicle length ~5m, consider collision if < 2m gap\n    \n    print(f\"Test Results:\")\n    print(f\"  Duration: {time_steps * sim.dt:.1f} seconds\")\n    print(f\"  Minimum distance: {min_distance:.2f} m\")\n    print(f\"  Collision: {'YES - FAIL' if collision else 'NO - PASS'}\")\n    print(f\"  Final ego velocity: {history['ego_v'][-1]:.2f} m/s\")\n    print(f\"  Final lead velocity: {lead_vehicle_speed:.2f} m/s\")\n    \n    # Visualize\n    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n    \n    # Position over time\n    ax1 = axes[0, 0]\n    ax1.plot(history['time'], history['ego_x'], 'b-', linewidth=2, label='Ego Vehicle')\n    ax1.plot(history['time'], history['lead_x'], 'r--', linewidth=2, label='Lead Vehicle')\n    ax1.set_xlabel('Time (s)', fontsize=11)\n    ax1.set_ylabel('Position (m)', fontsize=11)\n    ax1.set_title('Vehicle Positions', fontsize=13, fontweight='bold')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    \n    # Velocity over time\n    ax2 = axes[0, 1]\n    ax2.plot(history['time'], history['ego_v'], 'b-', linewidth=2, label='Ego Velocity')\n    ax2.axhline(y=acc.target_speed, color='g', linestyle=':', linewidth=1.5, label='Target Speed')\n    ax2.set_xlabel('Time (s)', fontsize=11)\n    ax2.set_ylabel('Velocity (m/s)', fontsize=11)\n    ax2.set_title('Ego Vehicle Velocity', fontsize=13, fontweight='bold')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    # Distance to lead vehicle\n    ax3 = axes[1, 0]\n    ax3.plot(history['time'], history['distance'], 'g-', linewidth=2)\n    ax3.axhline(y=acc.safe_distance, color='r', linestyle='--', linewidth=1.5, label='Safe Distance')\n    ax3.axhline(y=2.0, color='darkred', linestyle='--', linewidth=2, label='Collision Threshold')\n    ax3.set_xlabel('Time (s)', fontsize=11)\n    ax3.set_ylabel('Distance (m)', fontsize=11)\n    ax3.set_title('Following Distance', fontsize=13, fontweight='bold')\n    ax3.legend()\n    ax3.grid(True, alpha=0.3)\n    \n    # Acceleration command\n    ax4 = axes[1, 1]\n    ax4.plot(history['time'], history['acceleration'], 'orange', linewidth=2)\n    ax4.axhline(y=0, color='k', linestyle='-', linewidth=0.5)\n    ax4.set_xlabel('Time (s)', fontsize=11)\n    ax4.set_ylabel('Acceleration (m/s²)', fontsize=11)\n    ax4.set_title('Control Command', fontsize=13, fontweight='bold')\n    ax4.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Test verdict\n    print(f\"\\n{'='*50}\")\n    if not collision and min_distance >= acc.safe_distance * 0.8:\n        print(\"✓ TEST PASSED: ACC maintains safe distance\")\n    else:\n        print(\"✗ TEST FAILED: Safety requirements violated\")\n    print(f\"{'='*50}\")\n\ndemonstrate_sil_testing()"
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 3. Scenario-Based Testing and Edge Cases\n\nScenario-based testing focuses on specific situations rather than random driving miles.\n\n### What is a Scenario?\n\nA **scenario** is a specific driving situation with defined:\n- **Actors**: Ego vehicle, other vehicles, pedestrians\n- **Environment**: Road type, weather, lighting\n- **Events**: Actions and their timing\n\n**Example Scenario:**\n```\nScenario: Pedestrian Crosses at Unmarked Location\n- Road: Urban street, 30 mph limit\n- Weather: Clear, daytime\n- Event: Pedestrian steps off curb 20m ahead\n- Expected: Vehicle brakes, avoids collision\n```\n\n### Scenario Taxonomy\n\n**Functional Scenarios** (Abstract)\n- High-level description\n- Example: \"Vehicle performs lane change\"\n\n**Logical Scenarios** (Parameterized)\n- Specific parameter ranges\n- Example: \"Lane change at 50-70 mph, gap 20-40m\"\n\n**Concrete Scenarios** (Instantiated)\n- Exact parameters\n- Example: \"Lane change at 65 mph, 30m gap, wet road\"\n\n### Edge Cases and Corner Cases\n\n**Edge Case**: Extreme but possible situation\n- Example: Glare from setting sun directly ahead\n- Example: Truck with reflective surface causing sensor interference\n\n**Corner Case**: Combination of multiple edge cases\n- Example: Glare + wet road + pedestrian in shadow\n- Much rarer but higher risk\n\n### Scenario Generation Approaches\n\n**1. Expert-Defined**\n- Safety engineers list dangerous scenarios\n- Based on accident data, near-misses\n- Example: NHTSA pre-crash scenarios\n\n**2. Data-Driven**\n- Extract scenarios from real-world driving logs\n- Cluster similar situations\n- Example: Waymo extracts scenarios from 20M miles\n\n**3. Adversarial**\n- Systematically find failures\n- Optimization finds worst-case parameters\n- Example: Maximize collision probability\n\n**4. Combinatorial**\n- Test all combinations of parameters\n- Covering arrays reduce test count\n- Example: Pairwise testing of weather × lighting × speed\n\n### Critical Scenarios for AVs\n\n**Cut-In Scenarios:**\n- Vehicle suddenly enters ego lane\n- Varied: Speed difference, gap distance, driver reaction\n\n**Pedestrian Scenarios:**\n- Crossing (marked/unmarked crosswalk)\n- Occlusion (behind parked car)\n- Distracted (looking at phone)\n\n**Intersection Scenarios:**\n- Red light violation by other vehicle\n- Unprotected left turn (oncoming traffic)\n- Four-way stop coordination\n\n**Sensor Challenge Scenarios:**\n- Fog (reduces lidar/camera range)\n- Direct sunlight (camera saturation)\n- Reflective surfaces (radar false positives)\n\n### Coverage Metrics\n\n**Scenario Coverage**: % of identified scenarios tested\n\n**Parameter Coverage**: % of parameter space explored\n\n**Code Coverage**: % of software lines executed\n- Statement coverage\n- Branch coverage\n- Path coverage (impractical for large systems)\n\n**Requirement Coverage**: % of requirements validated",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 4. Ethics and Societal Implications\n\nAutonomous vehicles raise profound ethical questions about decision-making and responsibility.\n\n### The Trolley Problem for AVs\n\n**Classic Trolley Problem:**\nA runaway trolley will kill 5 people on the track. You can pull a lever to divert it to another track, killing 1 person instead. Do you pull the lever?\n\n**AV Adaptation:**\nAn AV's brakes fail. It can either:\n- **Option A**: Continue straight, hitting 5 pedestrians\n- **Option B**: Swerve, hitting 1 pedestrian on the sidewalk\n\n**Key Differences from Classic Problem:**\n1. **Uncertainty**: Sensors have errors, outcomes are probabilistic\n2. **Time Pressure**: Decision must be made in milliseconds\n3. **Preprogrammed**: Decision logic written before the situation occurs\n4. **Legal Liability**: Who is responsible for the programmed decision?\n\n### Ethical Frameworks\n\n**1. Utilitarianism**\n- Maximize overall well-being\n- \"Greatest good for the greatest number\"\n- AV implication: Minimize total harm (injuries, deaths)\n- Problem: May sacrifice individual for collective good\n\n**2. Deontology (Kant)**\n- Follow moral rules/duties\n- \"Never use people as means to an end\"\n- AV implication: Never intentionally harm anyone\n- Problem: May result in worse overall outcomes\n\n**3. Virtue Ethics**\n- Act as a virtuous person would\n- Consider character and intentions\n- AV implication: Design systems that reflect societal values\n- Problem: Vague guidance for specific situations\n\n**4. Social Contract Theory**\n- Rules people would agree to behind \"veil of ignorance\"\n- AV implication: Policies acceptable to all stakeholders\n- Problem: Different stakeholders have conflicting interests\n\n### Moral Machine Experiment\n\nMIT's Moral Machine collected 40 million decisions from millions of people worldwide on AV dilemmas.\n\n**Key Findings:**\n1. **Preference for fewer casualties**: Most prefer saving more lives\n2. **Preference for children over elderly**: Strong preference to save children\n3. **Preference for humans over animals**: Humans valued more\n4. **Cultural variation**: Eastern vs. Western cultures differ significantly\n5. **Preference for law-abiding**: Pedestrians crossing legally valued more\n\n**Problem**: No global consensus on AV ethics\n\n### Ethical Considerations in AV Design\n\n**1. Impartiality vs. Self-Preference**\n- Should AV protect passengers or minimize total harm?\n- Survey paradox: People want \"ethical\" AVs but prefer buying \"selfish\" AVs\n\n**2. Transparency vs. Complexity**\n- Should AV decision-making be explainable?\n- Deep learning models are often \"black boxes\"\n\n**3. Privacy vs. Safety**\n- AV cameras record everything\n- Who owns the data? How long is it kept?\n- Can it be subpoenaed in legal cases?\n\n**4. Accessibility vs. Profitability**\n- Will AVs reduce mobility inequality or increase it?\n- Who can afford autonomous mobility?\n\n**5. Employment Impact**\n- 3.5 million truck drivers in US\n- Taxi/Uber drivers\n- What happens to displaced workers?\n\n### Liability and Legal Frameworks\n\n**Who is Liable When AV Crashes?**\n\n**Traditional View (human-driven):**\n- Driver is liable for negligence\n- Sometimes: Vehicle manufacturer (defects)\n\n**AV Scenarios:**\n1. **Manufacturing Defect**: Manufacturer liable\n2. **Software Bug**: Software developer? OEM? Both?\n3. **Sensor Limitation (SOTIF)**: Who knew about limitation?\n4. **AI Decision**: How to prove negligence in ML system?\n5. **Cybersecurity Attack**: Hacker? Manufacturer for poor security?\n\n**Regulatory Approaches:**\n\n**Prescriptive Regulation:**\n- Specific rules (e.g., \"must brake within 2 seconds\")\n- Clear compliance criteria\n- Problem: Stifles innovation, can't anticipate all scenarios\n\n**Performance-Based Regulation:**\n- Outcomes required (e.g., \"must be safer than humans\")\n- Flexible implementation\n- Problem: Hard to measure, verify\n\n**Current Status:**\n- No comprehensive federal AV regulations in US (as of 2023)\n- Patchwork of state laws\n- EU proposed AI Act (includes AVs)\n- China has specific AV regulations\n\n### Social Acceptance\n\n**Factors Affecting Public Acceptance:**\n\n1. **Trust**: Reliability must be demonstrated\n2. **Control**: Loss of control anxiety\n3. **Transparency**: Understanding how decisions are made\n4. **Experience**: Exposure increases acceptance\n5. **Incidents**: High-profile crashes reduce trust significantly\n\n**Zero-Risk Fallacy:**\n- AVs held to impossibly high standard\n- Humans cause 1.3M deaths/year globally\n- Single AV fatality gets massive media attention\n- AVs must be significantly safer, not perfect",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Exercises\n\n### Exercise 1: Scenario Test Suite Design\n\n**Objective:** Design a comprehensive test suite for an emergency braking system using scenario-based testing.\n\n**Task:** Create a scenario database covering critical pedestrian crossing situations.\n\n**Instructions:**\n- Define at least 10 concrete scenarios varying:\n  - Pedestrian speed (slow walk, normal, running)\n  - Initial distance (10m, 20m, 30m)\n  - Ego vehicle speed (30, 50, 70 km/h)\n  - Occlusion (none, partial, full)\n  - Lighting (day, dusk, night)\n- For each scenario, specify:\n  - Expected outcome (stop before ped, collision, near-miss)\n  - Pass/fail criteria (e.g., TTC > 1.5s)\n  - Priority (P0=critical, P1=important, P2=nice-to-have)\n- Organize scenarios using equivalence partitioning\n- Calculate total test time assuming 2 min/scenario\n\n**Deliverables:**\n- Scenario database (table format)\n- Coverage analysis (what parameter combinations are covered?)\n- Test execution plan (order, priorities)\n\n### Exercise 2: SIL Testing with Fault Injection\n\n**Objective:** Extend the SIL simulator to test system robustness under sensor failures.\n\n**Task:** Implement fault injection in the `VehicleSimulator` class and test ACC behavior.\n\n**Instructions:**\n- Add fault injection capability to `simulate_sensor()`:\n  - Sensor dropout (returns no readings)\n  - Degraded accuracy (increased noise)\n  - Stuck reading (returns last valid reading)\n  - Delayed reading (latency simulation)\n- Test ACC with each fault type\n- Measure:\n  - Time to detect fault\n  - Safety impact (minimum distance maintained)\n  - Recovery behavior\n- Plot results comparing normal vs. faulty operation\n\n**Requirements:**\n- ACC must detect sensor fault within 0.5 seconds\n- ACC must enter safe state (gradual deceleration) upon fault\n- No collisions even with sensor failure\n\n### Exercise 3: Ethical Decision Framework\n\n**Objective:** Analyze ethical dilemmas in AV decision-making and propose a decision framework.\n\n**Task:** Create a decision tree for handling unavoidable collision scenarios.\n\n**Instructions:**\n1. Define 5 unavoidable collision scenarios:\n   - Example: Brakes fail, must choose between hitting pedestrian or swerving into barrier (risking passenger)\n   \n2. For each scenario, analyze:\n   - Utilitarian outcome (minimize total harm)\n   - Deontological outcome (follow rules, e.g., \"never swerve into pedestrian\")\n   - Legal considerations\n   - Public opinion (based on Moral Machine findings)\n\n3. Propose a decision framework:\n   - Hierarchy of factors to consider\n   - Weighting of different outcomes\n   - Tie-breaking rules\n\n4. Implement a simple decision function:\n   ```python\n   def choose_action(scenario):\n       # Input: Scenario with options and estimated outcomes\n       # Output: Chosen action with justification\n       pass\n   ```\n\n5. Test your framework on all 5 scenarios\n6. Compare your framework's decisions with:\n   - Human survey responses\n   - Other ethical frameworks\n   - Current AV manufacturer policies (if known)\n\n**Reflection Questions:**\n- Should AVs prioritize passengers or pedestrians?\n- Should probabilities matter? (50% chance of hitting 1 vs. 100% chance of hitting 0.3 people)\n- How should uncertainty affect decisions?\n- Is it ethical to program different behaviors for different markets?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Exercise Solutions\n\n# Exercise 1: Scenario Test Suite Design\n# TODO: Create scenario database\n#\n# Example structure:\n# import pandas as pd\n#\n# scenarios = [\n#     {\n#         'id': 'PED-001',\n#         'description': 'Adult pedestrian crosses at marked crosswalk',\n#         'ped_speed': 'normal',  # 1.4 m/s\n#         'initial_distance': 20,  # meters\n#         'ego_speed': 50,  # km/h\n#         'occlusion': 'none',\n#         'lighting': 'day',\n#         'expected_outcome': 'stop',\n#         'pass_criteria': 'TTC > 1.5s, no collision',\n#         'priority': 'P0'\n#     },\n#     {\n#         'id': 'PED-002',\n#         'description': 'Child runs into street from behind parked car',\n#         'ped_speed': 'running',  # 3.0 m/s\n#         'initial_distance': 10,  # meters\n#         'ego_speed': 30,  # km/h\n#         'occlusion': 'full',\n#         'lighting': 'day',\n#         'expected_outcome': 'near-miss or collision',\n#         'pass_criteria': 'emergency braking activated, speed < 20 km/h at impact',\n#         'priority': 'P0'\n#     },\n#     # ... add 8 more scenarios\n# ]\n#\n# df = pd.DataFrame(scenarios)\n# print(df[['id', 'description', 'priority', 'expected_outcome']])\n#\n# # Coverage analysis\n# print(\"\\nParameter Coverage:\")\n# print(f\"  Pedestrian speeds tested: {df['ped_speed'].nunique()}\")\n# print(f\"  Initial distances tested: {df['initial_distance'].nunique()}\")\n# print(f\"  Ego speeds tested: {df['ego_speed'].nunique()}\")\n# print(f\"  Occlusion types tested: {df['occlusion'].nunique()}\")\n# print(f\"  Lighting conditions tested: {df['lighting'].nunique()}\")\n#\n# # Test execution plan\n# p0_scenarios = df[df['priority'] == 'P0']\n# print(f\"\\nTest Execution Plan:\")\n# print(f\"  Total scenarios: {len(df)}\")\n# print(f\"  P0 (critical): {len(p0_scenarios)} - Test first\")\n# print(f\"  Estimated time: {len(df) * 2} minutes\")\n\n\n# Exercise 2: SIL Testing with Fault Injection\n# TODO: Extend VehicleSimulator with fault injection\n#\n# Example structure:\n# class FaultInjector:\n#     def __init__(self, fault_type='none', fault_start_time=0, fault_duration=float('inf')):\n#         self.fault_type = fault_type\n#         self.fault_start_time = fault_start_time\n#         self.fault_duration = fault_duration\n#         self.time = 0\n#         self.last_valid_reading = None\n#     \n#     def update(self, dt):\n#         self.time += dt\n#     \n#     def is_active(self):\n#         return (self.time >= self.fault_start_time and \n#                 self.time < self.fault_start_time + self.fault_duration)\n#     \n#     def apply_fault(self, readings):\n#         if not self.is_active():\n#             self.last_valid_reading = readings.copy() if readings else None\n#             return readings\n#         \n#         if self.fault_type == 'dropout':\n#             return []  # No readings\n#         \n#         elif self.fault_type == 'degraded':\n#             # Increase noise\n#             noisy_readings = []\n#             for r in readings:\n#                 noisy_r = SensorReading(\n#                     distance=r.distance + np.random.normal(0, 2.0),  # 20x normal noise\n#                     angle=r.angle + np.random.normal(0, 0.1),\n#                     object_type=r.object_type\n#                 )\n#                 noisy_readings.append(noisy_r)\n#             return noisy_readings\n#         \n#         elif self.fault_type == 'stuck':\n#             # Return last valid reading\n#             return self.last_valid_reading if self.last_valid_reading else []\n#         \n#         elif self.fault_type == 'delayed':\n#             # Return readings from 0.2s ago (would need history buffer)\n#             # Simplified: just add latency to distance\n#             delayed_readings = []\n#             for r in readings:\n#                 delayed_r = SensorReading(\n#                     distance=r.distance + 2.0,  # Approximate 0.2s delay at 10 m/s\n#                     angle=r.angle,\n#                     object_type=r.object_type\n#                 )\n#                 delayed_readings.append(delayed_r)\n#             return delayed_readings\n#\n# # Test each fault type\n# fault_types = ['none', 'dropout', 'degraded', 'stuck', 'delayed']\n# results = {}\n#\n# for fault_type in fault_types:\n#     sim = VehicleSimulator(dt=0.1)\n#     acc = SimpleACC(target_speed=20.0, safe_distance=10.0)\n#     fault_injector = FaultInjector(fault_type=fault_type, fault_start_time=5.0, fault_duration=3.0)\n#     \n#     # Run simulation (similar to demonstrate_sil_testing)\n#     # ... simulation loop with fault_injector.apply_fault(readings) ...\n#     \n#     results[fault_type] = {\n#         'min_distance': min_distance,\n#         'collision': collision,\n#         'fault_detected': True,  # Implement fault detection logic\n#         'detection_time': 0.3  # Time to detect fault\n#     }\n#\n# # Compare results\n# for fault_type, result in results.items():\n#     print(f\"{fault_type}: min_dist={result['min_distance']:.2f}m, \"\n#           f\"collision={result['collision']}, \"\n#           f\"detected={result['fault_detected']}\")\n\n\n# Exercise 3: Ethical Decision Framework\n# TODO: Implement ethical decision framework\n#\n# Example structure:\n# @dataclass\n# class Outcome:\n#     action: str\n#     passengers_harmed: int\n#     pedestrians_harmed: int\n#     property_damage: float\n#     probability: float = 1.0\n#     \n#     def expected_harm(self):\n#         # Weighted harm calculation\n#         return self.probability * (\n#             10.0 * self.passengers_harmed +\n#             10.0 * self.pedestrians_harmed +\n#             0.001 * self.property_damage\n#         )\n#\n# class EthicalDecisionFramework:\n#     def __init__(self, framework='utilitarian'):\n#         self.framework = framework\n#     \n#     def choose_action(self, outcomes: List[Outcome]) -> Outcome:\n#         if self.framework == 'utilitarian':\n#             # Minimize expected harm\n#             return min(outcomes, key=lambda o: o.expected_harm())\n#         \n#         elif self.framework == 'deontological':\n#             # Never intentionally harm pedestrians\n#             # Prefer actions that don't swerve into pedestrians\n#             pedestrian_safe = [o for o in outcomes if o.pedestrians_harmed == 0]\n#             if pedestrian_safe:\n#                 return min(pedestrian_safe, key=lambda o: o.expected_harm())\n#             else:\n#                 # All options harm pedestrians, choose least harm\n#                 return min(outcomes, key=lambda o: o.pedestrians_harmed)\n#         \n#         elif self.framework == 'passenger_priority':\n#             # Prioritize passengers\n#             return min(outcomes, key=lambda o: (o.passengers_harmed, o.expected_harm()))\n#\n# # Example scenario\n# scenario_brake_failure = [\n#     Outcome(action='continue_straight', passengers_harmed=0, pedestrians_harmed=5, property_damage=0),\n#     Outcome(action='swerve_right', passengers_harmed=2, pedestrians_harmed=0, property_damage=50000),\n#     Outcome(action='brake_hard', passengers_harmed=0, pedestrians_harmed=3, property_damage=0, probability=0.7)\n# ]\n#\n# # Test different frameworks\n# for framework_name in ['utilitarian', 'deontological', 'passenger_priority']:\n#     framework = EthicalDecisionFramework(framework_name)\n#     choice = framework.choose_action(scenario_brake_failure)\n#     print(f\"{framework_name}: chose '{choice.action}'\")\n#     print(f\"  Expected harm: {choice.expected_harm():.2f}\")\n#     print(f\"  Passengers harmed: {choice.passengers_harmed}\")\n#     print(f\"  Pedestrians harmed: {choice.pedestrians_harmed}\\n\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## References\n\n### Books - Testing & Validation\n\n1. **Ammann, P., & Offutt, J.** (2016). *Introduction to Software Testing* (2nd ed.). Cambridge University Press.\n   - Comprehensive software testing fundamentals\n   - Coverage criteria, test case generation\n\n2. **Copeland, L.** (2004). *A Practitioner's Guide to Software Test Design*. Artech House.\n   - Practical testing techniques\n   - Scenario-based testing methods\n\n### Papers - Testing & Validation\n\n3. **Kalra, N., & Paddock, S. M.** (2016). \"Driving to safety: How many miles of driving would it take to demonstrate autonomous vehicle reliability?\" *Transportation Research Part A: Policy and Practice*, 94, 182-193.\n   - Statistical challenges in AV validation\n   - 11 billion miles problem\n\n4. **Koopman, P., & Wagner, M.** (2016). \"Challenges in Autonomous Vehicle Testing and Validation.\" *SAE International Journal of Transportation Safety*, 4(1), 15-24.\n   - Comprehensive overview of AV testing challenges\n   - Scenario-based approaches\n\n5. **Tuncali, C. E., et al.** (2020). \"Simulation-Based Adversarial Test Generation for Autonomous Vehicles.\" *ACM/IEEE International Conference on Cyber-Physical Systems*.\n   - Adversarial testing methods\n   - Automated scenario generation\n\n6. **Riedmaier, S., et al.** (2020). \"Survey on Scenario-Based Safety Assessment of Automated Vehicles.\" *IEEE Access*, 8, 87456-87477.\n   - State-of-the-art scenario-based testing\n   - Comprehensive taxonomy\n\n7. **Peng, X., et al.** (2020). \"A Survey on Software Testing for Machine Learning.\" *ACM Transactions on Software Engineering and Methodology*.\n   - ML-specific testing challenges\n   - Relevant for AV perception systems\n\n### Papers - Simulation\n\n8. **Dosovitskiy, A., et al.** (2017). \"CARLA: An Open Urban Driving Simulator.\" *Conference on Robot Learning*.\n   - Open-source AV simulator\n   - Benchmarking platform\n\n9. **Rong, G., et al.** (2020). \"LGSVL Simulator: A High Fidelity Simulator for Autonomous Driving.\" *IEEE 23rd International Conference on Intelligent Transportation Systems*.\n   - High-fidelity simulation\n   - Sensor modeling\n\n10. **Quiter, C. L., & Ernst, M. D.** (2021). \"Simulation Fidelity in Autonomous Vehicle Safety Assessment.\" *IEEE Transactions on Intelligent Vehicles*.\n    - Sim2Real gap analysis\n    - Fidelity requirements\n\n### Papers - Ethics\n\n11. **Awad, E., et al.** (2018). \"The Moral Machine Experiment.\" *Nature*, 563(7729), 59-64.\n    - 40 million decisions from worldwide participants\n    - Cultural variations in ethical preferences\n    - Free data: https://www.moralmachine.net/\n\n12. **Bonnefon, J. F., Shariff, A., & Rahwan, I.** (2016). \"The Social Dilemma of Autonomous Vehicles.\" *Science*, 352(6293), 1573-1576.\n    - Survey on AV ethics\n    - Purchase paradox: want ethical AVs, buy selfish ones\n\n13. **Lin, P.** (2016). \"Why Ethics Matters for Autonomous Cars.\" In *Autonomous Driving* (pp. 69-85). Springer.\n    - Philosophical analysis\n    - Trolley problem adaptations\n\n14. **Goodall, N. J.** (2014). \"Ethical Decision Making During Automated Vehicle Crashes.\" *Transportation Research Record*, 2424(1), 58-65.\n    - Framework for crash-imminent decisions\n    - Legal and ethical considerations\n\n15. **Nyholm, S., & Smids, J.** (2016). \"The Ethics of Accident-Algorithms for Self-Driving Cars: An Applied Trolley Problem?\" *Ethical Theory and Moral Practice*, 19(5), 1275-1289.\n    - Critical analysis of trolley problem\n    - Differences from traditional ethics\n\n### Papers - Liability & Law\n\n16. **Vladeck, D. C.** (2014). \"Machines Without Principals: Liability Rules and Artificial Intelligence.\" *Washington Law Review*, 89, 117.\n    - Legal liability frameworks for AI\n    - Product liability vs. negligence\n\n17. **Gurney, J. K.** (2013). \"Sue My Car Not Me: Products Liability and Accidents Involving Autonomous Vehicles.\" *University of Illinois Journal of Law, Technology & Policy*, 2013, 247.\n    - Product liability for AVs\n    - Manufacturer vs. driver responsibility\n\n18. **Schellekens, M.** (2018). \"Self-Driving Cars and the Chilling Effect of Liability Law.\" *Computer Law & Security Review*, 31(4), 506-517.\n    - How liability affects AV development\n    - Regulatory recommendations\n\n### Industry Reports & Standards\n\n19. **UL 4600** - Standard for Safety for the Evaluation of Autonomous Products\n    - First comprehensive AV safety standard\n    - https://ul.org/UL4600\n\n20. **NHTSA - Automated Vehicles for Safety** (2020)\n    - Voluntary Safety Self-Assessment\n    - https://www.nhtsa.gov/vehicle-safety/automated-vehicles-safety\n\n21. **SAE J3016** - Taxonomy and Definitions for Automated Driving\n    - Levels of automation (0-5)\n    - ODD definitions\n\n22. **BSI PAS 1883** - Operational Design Domain (ODD) Taxonomy\n    - Systematic ODD specification\n    - https://www.bsigroup.com/\n\n### Tools & Simulators\n\n23. **CARLA Simulator**\n    - Open-source AV simulator\n    - https://carla.org/\n    - Python API, sensor simulation\n\n24. **LGSVL Simulator**\n    - Unity-based AV simulator\n    - https://www.svlsimulator.com/\n    - Digital twin capability\n\n25. **SUMO** - Simulation of Urban MObility\n    - Traffic flow simulation\n    - https://www.eclipse.org/sumo/\n\n26. **OpenScenario & OpenDrive**\n    - Scenario description standards\n    - https://www.asam.net/standards/detail/openscenario/\n    - Industry-standard formats\n\n### Datasets\n\n27. **nuScenes**\n    - Full sensor suite dataset\n    - https://www.nuscenes.org/\n    - Useful for testing perception\n\n28. **Waymo Open Dataset**\n    - Large-scale driving data\n    - https://waymo.com/open/\n    - Diverse scenarios\n\n29. **KITTI**\n    - Classic AV benchmark\n    - http://www.cvlibs.net/datasets/kitti/\n    - Stereo, lidar, GPS\n\n### Ethics Resources\n\n30. **Moral Machine Platform**\n    - Interactive ethical dilemma explorer\n    - https://www.moralmachine.net/\n    - Research and education tool\n\n31. **IEEE - Ethically Aligned Design**\n    - Guide for autonomous systems\n    - https://standards.ieee.org/industry-connections/ec/ead-v1/\n    - Ethical considerations framework\n\n### Courses\n\n32. **Coursera - Self-Driving Cars Specialization** (University of Toronto)\n    - Module 4: Safety assurance\n    - Testing and validation\n\n33. **edX - Autonomous Mobile Robots** (ETH Zurich)\n    - Testing and simulation modules\n\n34. **MIT OpenCourseWare - Ethics of Technology**\n    - Philosophical foundations\n    - Case studies including AVs"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}